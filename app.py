"""
Video Style Editor - ä½¿ç”¨Qwen Image Edit APIè¿›è¡Œè§†é¢‘é£æ ¼ç¼–è¾‘
"""

import os
import base64
import mimetypes
import tempfile
import shutil
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

import random
import cv2
import numpy as np
from PIL import Image
import gradio as gr
from dotenv import load_dotenv
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é»˜è®¤è¾“å‡ºç›®å½•
DEFAULT_OUTPUT_DIR = Path("./output")
DEFAULT_OUTPUT_DIR.mkdir(exist_ok=True)


def encode_image_to_base64(image_path: str) -> str:
    """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64æ ¼å¼"""
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith("image/"):
        mime_type = "image/png"

    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
    return f"data:{mime_type};base64,{encoded_string}"


def extract_frames(video_path: str, interval: float, output_dir: Path) -> tuple[list[str], float, tuple[int, int]]:
    """
    ä»è§†é¢‘ä¸­æŒ‰æŒ‡å®šæ—¶é—´é—´éš”æå–å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        interval: æå–é—´éš”ï¼ˆç§’ï¼‰
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        (å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨, fps, (å®½åº¦, é«˜åº¦))
    """
    logger.info(f"å¼€å§‹æå–å¸§: {video_path}, é—´éš”: {interval}ç§’")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    logger.info(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.2f}fps, æ€»å¸§æ•°: {total_frames}, æ—¶é•¿: {duration:.2f}ç§’")

    # è®¡ç®—è¦æå–çš„å¸§
    frame_interval = int(fps * interval)
    if frame_interval < 1:
        frame_interval = 1

    frames_dir = output_dir / "original_frames"
    frames_dir.mkdir(exist_ok=True)

    frame_paths = []
    frame_idx = 0
    extracted_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_idx % frame_interval == 0:
            frame_path = frames_dir / f"frame_{extracted_count:06d}.png"
            cv2.imwrite(str(frame_path), frame)
            frame_paths.append(str(frame_path))
            extracted_count += 1

        frame_idx += 1

    cap.release()
    logger.info(f"å¸§æå–å®Œæˆ: å…±æå– {extracted_count} å¸§")

    return frame_paths, fps, (width, height)


def extract_audio(video_path: str, output_dir: Path) -> str | None:
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    logger.info(f"å¼€å§‹æå–éŸ³é¢‘: {video_path}")
    try:
        from moviepy import VideoFileClip

        audio_path = output_dir / "audio.mp3"
        video = VideoFileClip(video_path)

        if video.audio is not None:
            logger.info("æ£€æµ‹åˆ°éŸ³é¢‘è½¨é“ï¼Œæ­£åœ¨æå–...")
            video.audio.write_audiofile(str(audio_path), logger=None)
            video.close()
            logger.info(f"éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
            return str(audio_path)

        video.close()
        logger.info("è§†é¢‘æ²¡æœ‰éŸ³é¢‘è½¨é“")
        return None
    except Exception as e:
        logger.error(f"æå–éŸ³é¢‘å¤±è´¥: {e}")
        return None


def call_qwen_image_edit(
    image_path: str,
    prompt: str,
    api_key: str,
    output_path: str,
    size: str | None = None,
) -> str:
    """
    è°ƒç”¨Qwen Image Edit APIç¼–è¾‘å›¾ç‰‡

    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        size: è¾“å‡ºå°ºå¯¸ (å¦‚ "1024*1024")

    Returns:
        è¾“å‡ºå›¾ç‰‡è·¯å¾„
    """
    import dashscope
    from dashscope import MultiModalConversation
    import requests

    dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'

    # ç¼–ç å›¾ç‰‡
    image_base64 = encode_image_to_base64(image_path)

    messages = [
        {
            "role": "user",
            "content": [
                {"image": image_base64},
                {"text": prompt}
            ]
        }
    ]

    # æ„å»ºè¯·æ±‚å‚æ•°
    kwargs = {
        "api_key": api_key,
        "model": "qwen-image-edit-plus",
        "messages": messages,
        "stream": False,
        "n": 1,
        "watermark": False,
        "prompt_extend": True,
    }

    if size:
        kwargs["size"] = size

    logger.debug(f"è°ƒç”¨Qwen APIå¤„ç†å›¾ç‰‡: {image_path}")
    response = MultiModalConversation.call(**kwargs)

    if response.status_code == 200:
        # è·å–ç”Ÿæˆçš„å›¾ç‰‡URL
        image_url = response.output.choices[0].message.content[0]['image']
        logger.debug(f"APIè¿”å›æˆåŠŸï¼Œæ­£åœ¨ä¸‹è½½å›¾ç‰‡...")

        # ä¸‹è½½å›¾ç‰‡
        img_response = requests.get(image_url)
        if img_response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(img_response.content)
            logger.debug(f"å›¾ç‰‡ä¿å­˜å®Œæˆ: {output_path}")
            return output_path
        else:
            logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: HTTP {img_response.status_code}")
            raise Exception(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: HTTP {img_response.status_code}")
    else:
        logger.error(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")
        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")


def process_frames_parallel(
    frame_paths: list[str],
    prompt: str,
    api_key: str,
    output_dir: Path,
    size: str | None = None,
    max_workers: int = 3,
    progress_callback=None,
) -> list[str]:
    """
    å¹¶è¡Œå¤„ç†å¤šä¸ªå¸§

    Args:
        frame_paths: åŸå§‹å¸§è·¯å¾„åˆ—è¡¨
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        output_dir: è¾“å‡ºç›®å½•
        size: è¾“å‡ºå°ºå¯¸
        max_workers: æœ€å¤§å¹¶è¡Œæ•°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

    Returns:
        ç¼–è¾‘åçš„å¸§è·¯å¾„åˆ—è¡¨
    """
    logger.info(f"å¼€å§‹å¹¶è¡Œå¤„ç†å¸§: å…± {len(frame_paths)} å¸§, å¹¶è¡Œæ•°: {max_workers}")
    edited_dir = output_dir / "edited_frames"
    edited_dir.mkdir(exist_ok=True)

    edited_paths = [None] * len(frame_paths)
    completed = 0
    total = len(frame_paths)

    def process_single(args):
        idx, frame_path = args
        output_path = str(edited_dir / f"edited_{idx:06d}.png")
        try:
            result = call_qwen_image_edit(frame_path, prompt, api_key, output_path, size)
            return idx, result, None
        except Exception as e:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾
            shutil.copy(frame_path, output_path)
            return idx, output_path, str(e)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(process_single, (i, path)): i
                   for i, path in enumerate(frame_paths)}

        for future in as_completed(futures):
            idx, result_path, error = future.result()
            edited_paths[idx] = result_path
            completed += 1

            if error:
                logger.warning(f"å¸§ {idx} å¤„ç†å‡ºé”™: {error}")
            else:
                logger.info(f"å¸§ {idx} å¤„ç†å®Œæˆ ({completed}/{total})")

            if progress_callback:
                progress_callback(completed / total, f"å·²å¤„ç† {completed}/{total} å¸§")

    logger.info(f"æ‰€æœ‰å¸§å¤„ç†å®Œæˆ: {completed}/{total}")
    return edited_paths


def create_pan_effect_clip(
    image_path: str,
    duration: float,
    target_size: tuple[int, int],
    pan_range: float,
    fps: float,
) -> "ImageClip":
    """
    ä¸ºå•å¼ å›¾ç‰‡åˆ›å»ºå¹³ç§»åŠ¨æ•ˆçš„è§†é¢‘ç‰‡æ®µ

    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        duration: ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
        target_size: ç›®æ ‡å°ºå¯¸ (å®½åº¦, é«˜åº¦)
        pan_range: å¹³ç§»èŒƒå›´æ¯”ä¾‹ï¼ˆå¦‚ 0.05 è¡¨ç¤º 5%ï¼‰
        fps: å¸§ç‡

    Returns:
        å¸¦å¹³ç§»åŠ¨æ•ˆçš„è§†é¢‘ç‰‡æ®µ
    """
    from moviepy import ImageClip

    # åŠ è½½åŸå›¾å¹¶æ”¾å¤§
    img = Image.open(image_path)
    original_size = img.size

    # è®¡ç®—æ”¾å¤§åçš„å°ºå¯¸ï¼ˆæ”¾å¤§ pan_range * 2 ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç§»åŠ¨ç©ºé—´ï¼‰
    scale_factor = 1 + pan_range * 2
    enlarged_size = (
        int(target_size[0] * scale_factor),
        int(target_size[1] * scale_factor),
    )

    # æ”¾å¤§å›¾ç‰‡
    img_enlarged = img.resize(enlarged_size, Image.Resampling.LANCZOS)
    img.close()

    # ä¿å­˜æ”¾å¤§åçš„ä¸´æ—¶å›¾ç‰‡
    temp_dir = Path(image_path).parent
    temp_path = temp_dir / f"_temp_enlarged_{Path(image_path).stem}.png"
    img_enlarged.save(temp_path)
    img_enlarged.close()

    # è®¡ç®—æœ€å¤§åç§»é‡
    max_offset_x = enlarged_size[0] - target_size[0]
    max_offset_y = enlarged_size[1] - target_size[1]

    # éšæœºé€‰æ‹©å¹³ç§»æ–¹å‘ï¼š0=å·¦åˆ°å³, 1=å³åˆ°å·¦, 2=ä¸Šåˆ°ä¸‹, 3=ä¸‹åˆ°ä¸Š
    direction = random.randint(0, 3)

    # è®¾ç½®èµ·å§‹å’Œç»“æŸä½ç½®
    if direction == 0:  # å·¦åˆ°å³
        start_x, end_x = 0, max_offset_x
        start_y = end_y = max_offset_y // 2
    elif direction == 1:  # å³åˆ°å·¦
        start_x, end_x = max_offset_x, 0
        start_y = end_y = max_offset_y // 2
    elif direction == 2:  # ä¸Šåˆ°ä¸‹
        start_x = end_x = max_offset_x // 2
        start_y, end_y = 0, max_offset_y
    else:  # ä¸‹åˆ°ä¸Š
        start_x = end_x = max_offset_x // 2
        start_y, end_y = max_offset_y, 0

    # åˆ›å»ºå›¾ç‰‡clip
    clip = ImageClip(str(temp_path)).with_duration(duration)

    # å®šä¹‰è£å‰ªå‡½æ•°å®ç°å¹³ç§»æ•ˆæœ
    def make_frame(get_frame, t):
        # è®¡ç®—å½“å‰æ—¶é—´çš„è¿›åº¦ï¼ˆ0åˆ°1ï¼‰
        progress = t / duration if duration > 0 else 0
        # çº¿æ€§æ’å€¼è®¡ç®—å½“å‰åç§»
        current_x = int(start_x + (end_x - start_x) * progress)
        current_y = int(start_y + (end_y - start_y) * progress)
        # è·å–å½“å‰å¸§å¹¶è£å‰ª
        frame = get_frame(t)
        cropped = frame[current_y:current_y + target_size[1], current_x:current_x + target_size[0]]
        return cropped

    # åº”ç”¨å¹³ç§»æ•ˆæœ
    clip = clip.transform(make_frame)

    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    if temp_path.exists():
        temp_path.unlink()

    return clip


def create_video_from_frames(
    frame_paths: list[str],
    output_path: str,
    fps: float,
    audio_path: str | None = None,
    pan_range: float = 0.0,
) -> str:
    """
    ä»å¸§åºåˆ—åˆ›å»ºè§†é¢‘

    Args:
        frame_paths: å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        fps: å¸§ç‡
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        pan_range: å¹³ç§»åŠ¨æ•ˆèŒƒå›´æ¯”ä¾‹ï¼ˆå¦‚ 0.05 è¡¨ç¤º 5%ï¼‰ï¼Œ0 è¡¨ç¤ºæ— åŠ¨æ•ˆ

    Returns:
        è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    pan_enabled = pan_range > 0
    logger.info(f"å¼€å§‹åˆ›å»ºè§†é¢‘: {len(frame_paths)} å¸§, {fps}fps, å¹³ç§»åŠ¨æ•ˆ: {'å¯ç”¨ ' + str(int(pan_range*100)) + '%' if pan_enabled else 'å…³é—­'}")
    from moviepy import ImageSequenceClip, AudioFileClip, concatenate_videoclips

    # æ£€æŸ¥å¹¶ç»Ÿä¸€æ‰€æœ‰å¸§çš„å°ºå¯¸
    logger.info("æ£€æŸ¥å¸§å°ºå¯¸...")
    frame_sizes = []
    for path in frame_paths:
        img = Image.open(path)
        frame_sizes.append(img.size)
        img.close()

    # ä½¿ç”¨ç¬¬ä¸€å¸§çš„å°ºå¯¸ä½œä¸ºç›®æ ‡å°ºå¯¸
    target_size = frame_sizes[0]
    size_mismatch = any(size != target_size for size in frame_sizes)

    if size_mismatch:
        logger.warning(f"æ£€æµ‹åˆ°å¸§å°ºå¯¸ä¸ä¸€è‡´ï¼Œå°†ç»Ÿä¸€è°ƒæ•´ä¸º {target_size[0]}x{target_size[1]}")
        for i, (path, size) in enumerate(zip(frame_paths, frame_sizes)):
            if size != target_size:
                logger.debug(f"è°ƒæ•´å¸§ {i} å°ºå¯¸: {size} -> {target_size}")
                img = Image.open(path)
                img_resized = img.resize(target_size, Image.Resampling.LANCZOS)
                img_resized.save(path)
                img.close()
                img_resized.close()
        logger.info("å¸§å°ºå¯¸ç»Ÿä¸€å®Œæˆ")

    # åˆ›å»ºè§†é¢‘
    if pan_enabled:
        # ä½¿ç”¨å¹³ç§»åŠ¨æ•ˆï¼šä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºå¸¦å¹³ç§»æ•ˆæœçš„clipï¼Œç„¶åæ‹¼æ¥
        logger.info("æ­£åœ¨ä¸ºæ¯å¸§åˆ›å»ºå¹³ç§»åŠ¨æ•ˆ...")
        # è®¡ç®—æ¯å¸§çš„æŒç»­æ—¶é—´
        frame_duration = 1.0 / fps
        clips = []
        for i, frame_path in enumerate(frame_paths):
            pan_clip = create_pan_effect_clip(
                frame_path,
                duration=frame_duration,
                target_size=target_size,
                pan_range=pan_range,
                fps=fps,
            )
            clips.append(pan_clip)
            if (i + 1) % 10 == 0:
                logger.debug(f"å·²å¤„ç† {i + 1}/{len(frame_paths)} å¸§çš„å¹³ç§»åŠ¨æ•ˆ")
        # æ‹¼æ¥æ‰€æœ‰clip
        clip = concatenate_videoclips(clips, method="compose")
        logger.info(f"å¹³ç§»åŠ¨æ•ˆè§†é¢‘ç‰‡æ®µåˆ›å»ºå®Œæˆ, æ—¶é•¿: {clip.duration:.2f}ç§’")
    else:
        # æ— å¹³ç§»åŠ¨æ•ˆï¼Œä½¿ç”¨åŸæœ‰æ–¹å¼
        clip = ImageSequenceClip(frame_paths, fps=fps)
        logger.info(f"è§†é¢‘ç‰‡æ®µåˆ›å»ºå®Œæˆ, æ—¶é•¿: {clip.duration:.2f}ç§’")

    # æ·»åŠ éŸ³é¢‘
    audio = None
    if audio_path and os.path.exists(audio_path):
        logger.info(f"æ­£åœ¨æ·»åŠ éŸ³é¢‘: {audio_path}")
        audio = AudioFileClip(audio_path)
        # ç¡®ä¿éŸ³é¢‘é•¿åº¦ä¸è§†é¢‘åŒ¹é…
        if audio.duration > clip.duration:
            audio = audio.subclipped(0, clip.duration)
        clip = clip.with_audio(audio)
        logger.info("éŸ³é¢‘æ·»åŠ å®Œæˆ")

    # è¾“å‡ºè§†é¢‘
    logger.info(f"æ­£åœ¨ç¼–ç è¾“å‡ºè§†é¢‘: {output_path}")
    clip.write_videofile(
        output_path,
        fps=fps,
        codec='libx264',
        audio_codec='aac',
        logger=None,
    )

    clip.close()
    if audio is not None:
        audio.close()

    logger.info(f"è§†é¢‘åˆ›å»ºå®Œæˆ: {output_path}")
    return output_path


def process_video(
    video_path: str,
    interval: float,
    prompt: str,
    api_key: str,
    output_size: str,
    max_workers: int,
    pan_range: float,
    progress=gr.Progress(),
) -> tuple[str, list[tuple[str, str]], str]:
    """
    å¤„ç†è§†é¢‘çš„ä¸»å‡½æ•°

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        interval: å¸§æå–é—´éš”ï¼ˆç§’ï¼‰
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        output_size: è¾“å‡ºå°ºå¯¸
        max_workers: å¹¶è¡Œå¤„ç†æ•°
        pan_range: å¹³ç§»åŠ¨æ•ˆèŒƒå›´ï¼ˆ0-20%ï¼‰
        progress: è¿›åº¦å›è°ƒ

    Returns:
        (è¾“å‡ºè§†é¢‘è·¯å¾„, é¢„è§ˆå›¾ç‰‡åˆ—è¡¨, çŠ¶æ€æ¶ˆæ¯)
    """
    if not video_path:
        return None, [], "è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶"

    if not api_key:
        return None, [], "è¯·è¾“å…¥API Key"

    if not prompt:
        return None, [], "è¯·è¾“å…¥ç¼–è¾‘æŒ‡ä»¤"

    # åˆ›å»ºå·¥ä½œç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    work_dir = DEFAULT_OUTPUT_DIR / f"job_{timestamp}"
    work_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"========== å¼€å§‹å¤„ç†è§†é¢‘ ==========")
    logger.info(f"è§†é¢‘è·¯å¾„: {video_path}")
    logger.info(f"å·¥ä½œç›®å½•: {work_dir}")
    # pan_range ä» UI ä¼ å…¥çš„æ˜¯ç™¾åˆ†æ¯”å€¼ï¼ˆ0-20ï¼‰ï¼Œè½¬æ¢ä¸ºæ¯”ä¾‹ï¼ˆ0-0.20ï¼‰
    pan_range_ratio = pan_range / 100.0
    pan_range_pct = int(pan_range)
    logger.info(f"å‚æ•°: é—´éš”={interval}ç§’, å¹¶è¡Œæ•°={max_workers}, å°ºå¯¸={output_size}, å¹³ç§»åŠ¨æ•ˆ={pan_range_pct}%")

    try:
        # æ­¥éª¤1: æå–å¸§
        logger.info("[æ­¥éª¤1/4] å¼€å§‹æå–è§†é¢‘å¸§...")
        progress(0.1, desc="æ­£åœ¨æå–è§†é¢‘å¸§...")
        frame_paths, fps, (width, height) = extract_frames(video_path, interval, work_dir)

        if not frame_paths:
            logger.error("æ— æ³•ä»è§†é¢‘ä¸­æå–å¸§")
            return None, [], "æ— æ³•ä»è§†é¢‘ä¸­æå–å¸§"

        progress(0.15, desc=f"å·²æå– {len(frame_paths)} å¸§")

        # æ­¥éª¤2: æå–éŸ³é¢‘
        logger.info("[æ­¥éª¤2/4] å¼€å§‹æå–éŸ³é¢‘...")
        progress(0.2, desc="æ­£åœ¨æå–éŸ³é¢‘...")
        audio_path = extract_audio(video_path, work_dir)

        # æ­¥éª¤3: å¤„ç†å¸§
        logger.info("[æ­¥éª¤3/4] å¼€å§‹å¤„ç†å¸§...")
        progress(0.25, desc="æ­£åœ¨å¤„ç†å¸§...")

        # è§£æè¾“å‡ºå°ºå¯¸
        size = output_size if output_size and output_size != "åŸå§‹å°ºå¯¸" else None

        def update_progress(ratio, msg):
            # å¸§å¤„ç†å 25%-85%çš„è¿›åº¦
            progress(0.25 + ratio * 0.6, desc=msg)

        edited_paths = process_frames_parallel(
            frame_paths,
            prompt,
            api_key,
            work_dir,
            size=size,
            max_workers=max_workers,
            progress_callback=update_progress,
        )

        # æ­¥éª¤4: ç”Ÿæˆè§†é¢‘
        logger.info("[æ­¥éª¤4/4] å¼€å§‹åˆæˆè§†é¢‘...")
        progress(0.9, desc="æ­£åœ¨åˆæˆè§†é¢‘...")
        output_video_path = str(work_dir / "output.mp4")
        create_video_from_frames(edited_paths, output_video_path, fps, audio_path, pan_range_ratio)

        progress(1.0, desc="å¤„ç†å®Œæˆ!")

        # å‡†å¤‡é¢„è§ˆå›¾ç‰‡ï¼ˆæ˜¾ç¤ºåŸå›¾å’Œç¼–è¾‘åçš„å¯¹æ¯”ï¼‰
        preview_images = []
        step = max(1, len(frame_paths) // 6)  # æœ€å¤šæ˜¾ç¤º6ç»„å¯¹æ¯”
        for i in range(0, len(frame_paths), step):
            if i < len(edited_paths) and edited_paths[i]:
                preview_images.append((frame_paths[i], f"åŸå§‹å¸§ {i+1}"))
                preview_images.append((edited_paths[i], f"ç¼–è¾‘å {i+1}"))

        status = f"å¤„ç†å®Œæˆ! å…±å¤„ç† {len(frame_paths)} å¸§ï¼Œè¾“å‡ºè§†é¢‘: {output_video_path}"
        logger.info(f"========== è§†é¢‘å¤„ç†å®Œæˆ ==========")
        logger.info(f"è¾“å‡ºæ–‡ä»¶: {output_video_path}")
        return output_video_path, preview_images, status

    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {str(e)}", exc_info=True)
        return None, [], f"å¤„ç†å¤±è´¥: {str(e)}"


def create_ui():
    """åˆ›å»ºGradioç•Œé¢"""

    with gr.Blocks(title="è§†é¢‘é£æ ¼ç¼–è¾‘å™¨", theme=gr.themes.Soft()) as app:
        gr.Markdown("""
        # ğŸ¬ è§†é¢‘é£æ ¼ç¼–è¾‘å™¨

        ä½¿ç”¨é€šä¹‰åƒé—® Qwen Image Edit API å¯¹è§†é¢‘è¿›è¡Œé£æ ¼è½¬æ¢ã€‚
        ä¸Šä¼ è§†é¢‘åï¼Œä¼šæŒ‰æŒ‡å®šæ—¶é—´é—´éš”æå–å¸§ï¼Œä½¿ç”¨AIç¼–è¾‘æ¯ä¸€å¸§ï¼Œç„¶åé‡æ–°åˆæˆè§†é¢‘ã€‚
        """)

        with gr.Row():
            with gr.Column(scale=1):
                # è¾“å…¥åŒºåŸŸ
                gr.Markdown("### ğŸ“ è¾“å…¥è®¾ç½®")

                video_input = gr.Video(
                    label="ä¸Šä¼ è§†é¢‘",
                    sources=["upload"],
                )

                api_key_input = gr.Textbox(
                    label="DashScope API Key",
                    placeholder="è¯·è¾“å…¥æ‚¨çš„API Key",
                    type="password",
                    value=os.getenv("DASHSCOPE_API_KEY", ""),
                )

                prompt_input = gr.Textbox(
                    label="ç¼–è¾‘æŒ‡ä»¤",
                    placeholder="æè¿°æ‚¨æƒ³è¦çš„è§†è§’/æ™¯åˆ«å˜åŒ–ï¼Œä¾‹å¦‚ï¼šå°†ç”»é¢è½¬æ¢ä¸ºä¿¯è§†è§’åº¦ï¼Œå¢åŠ æ™¯æ·±æ•ˆæœ",
                    lines=3,
                    value="å°†ç”»é¢è½¬æ¢ä¸ºç”µå½±çº§åˆ«çš„å¹¿è§’é•œå¤´æ•ˆæœï¼Œå¢å¼ºæ™¯æ·±å’Œç©ºé—´æ„Ÿ",
                )

                with gr.Row():
                    interval_input = gr.Slider(
                        label="å¸§æå–é—´éš”ï¼ˆç§’ï¼‰",
                        minimum=0.1,
                        maximum=10.0,
                        value=1.0,
                        step=0.1,
                        info="é—´éš”è¶Šå°ï¼Œå¸§æ•°è¶Šå¤šï¼Œå¤„ç†æ—¶é—´è¶Šé•¿",
                    )

                    workers_input = gr.Slider(
                        label="å¹¶è¡Œå¤„ç†æ•°",
                        minimum=1,
                        maximum=5,
                        value=2,
                        step=1,
                        info="åŒæ—¶å¤„ç†çš„å¸§æ•°ï¼Œå»ºè®®2-3",
                    )

                size_input = gr.Dropdown(
                    label="è¾“å‡ºå°ºå¯¸",
                    choices=["åŸå§‹å°ºå¯¸", "512*512", "768*768", "1024*1024", "1024*768", "768*1024"],
                    value="åŸå§‹å°ºå¯¸",
                    info="è®¾ç½®ç¼–è¾‘åå›¾ç‰‡çš„åˆ†è¾¨ç‡",
                )

                pan_range_input = gr.Slider(
                    label="å¹³ç§»åŠ¨æ•ˆèŒƒå›´ï¼ˆ%ï¼‰",
                    minimum=0,
                    maximum=20,
                    value=0,
                    step=1,
                    info="å›¾ç‰‡å¹³ç§»èŒƒå›´ï¼Œ0è¡¨ç¤ºå…³é—­ï¼Œ5-10%æ•ˆæœè¾ƒè‡ªç„¶ï¼Œæ–¹å‘éšæœº",
                )

                process_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary", size="lg")

            with gr.Column(scale=1):
                # è¾“å‡ºåŒºåŸŸ
                gr.Markdown("### ğŸ“º è¾“å‡ºç»“æœ")

                status_output = gr.Textbox(
                    label="å¤„ç†çŠ¶æ€",
                    interactive=False,
                )

                video_output = gr.Video(
                    label="è¾“å‡ºè§†é¢‘",
                )

        # é¢„è§ˆåŒºåŸŸ
        gr.Markdown("### ğŸ–¼ï¸ å¸§é¢„è§ˆï¼ˆåŸå›¾ vs ç¼–è¾‘åï¼‰")
        preview_gallery = gr.Gallery(
            label="å¸§å¯¹æ¯”é¢„è§ˆ",
            columns=4,
            rows=2,
            height="auto",
            object_fit="contain",
        )

        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ## ä½¿ç”¨æ­¥éª¤

            1. **è·å–API Key**: å‰å¾€ [é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°](https://bailian.console.alibabacloud.com/) æ³¨å†Œå¹¶è·å– DashScope API Key
            2. **ä¸Šä¼ è§†é¢‘**: æ”¯æŒå¸¸è§è§†é¢‘æ ¼å¼ï¼ˆMP4, AVI, MOVç­‰ï¼‰
            3. **è®¾ç½®å‚æ•°**:
               - **å¸§æå–é—´éš”**: å»ºè®®0.5-2ç§’ï¼Œé—´éš”è¶Šå°æ•ˆæœè¶Šæµç•…ä½†å¤„ç†æ—¶é—´è¶Šé•¿
               - **ç¼–è¾‘æŒ‡ä»¤**: æè¿°æ‚¨æƒ³è¦çš„è§†è§‰æ•ˆæœå˜åŒ–
               - **å¹¶è¡Œå¤„ç†æ•°**: å»ºè®®2-3ï¼Œè¿‡é«˜å¯èƒ½è§¦å‘APIé™æµ
            4. **å¼€å§‹å¤„ç†**: ç‚¹å‡»æŒ‰é’®åç­‰å¾…å¤„ç†å®Œæˆ
            5. **æŸ¥çœ‹ç»“æœ**: é¢„è§ˆç¼–è¾‘åçš„å¸§å¹¶ä¸‹è½½è¾“å‡ºè§†é¢‘

            ## ç¼–è¾‘æŒ‡ä»¤ç¤ºä¾‹

            - å°†ç”»é¢è½¬æ¢ä¸ºä¿¯è§†è§’åº¦
            - å¢åŠ ç”µå½±çº§åˆ«çš„æ™¯æ·±æ•ˆæœ
            - è½¬æ¢ä¸ºå¹¿è§’é•œå¤´è§†è§’
            - å¢å¼ºç”»é¢çš„ç©ºé—´å±‚æ¬¡æ„Ÿ
            - å°†è¿‘æ™¯è½¬æ¢ä¸ºä¸­æ™¯æ„å›¾
            - æ·»åŠ æŸ”å’Œçš„èƒŒæ™¯è™šåŒ–æ•ˆæœ

            ## æ³¨æ„äº‹é¡¹

            - è§†é¢‘è¾ƒé•¿æ—¶å¤„ç†æ—¶é—´å¯èƒ½è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…
            - APIè°ƒç”¨ä¼šäº§ç”Ÿè´¹ç”¨ï¼Œè¯·æ³¨æ„æ§åˆ¶å¸§æ•°
            - å»ºè®®å…ˆç”¨çŸ­è§†é¢‘æµ‹è¯•æ•ˆæœ
            """)

        # ç»‘å®šäº‹ä»¶
        process_btn.click(
            fn=process_video,
            inputs=[
                video_input,
                interval_input,
                prompt_input,
                api_key_input,
                size_input,
                workers_input,
                pan_range_input,
            ],
            outputs=[video_output, preview_gallery, status_output],
            show_progress=True,
        )

    return app


def main():
    """ä¸»å‡½æ•°"""
    app = create_ui()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
    )


if __name__ == "__main__":
    main()
