"""
Video Style Editor - ä½¿ç”¨Qwen Image Edit APIè¿›è¡Œè§†é¢‘é£æ ¼ç¼–è¾‘
"""

import os
import base64
import mimetypes
import tempfile
import shutil
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

import cv2
import numpy as np
from PIL import Image
import gradio as gr
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é»˜è®¤è¾“å‡ºç›®å½•
DEFAULT_OUTPUT_DIR = Path("./output")
DEFAULT_OUTPUT_DIR.mkdir(exist_ok=True)


def encode_image_to_base64(image_path: str) -> str:
    """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64æ ¼å¼"""
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith("image/"):
        mime_type = "image/png"

    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
    return f"data:{mime_type};base64,{encoded_string}"


def extract_frames(video_path: str, interval: float, output_dir: Path) -> tuple[list[str], float, tuple[int, int]]:
    """
    ä»è§†é¢‘ä¸­æŒ‰æŒ‡å®šæ—¶é—´é—´éš”æå–å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        interval: æå–é—´éš”ï¼ˆç§’ï¼‰
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        (å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨, fps, (å®½åº¦, é«˜åº¦))
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps

    # è®¡ç®—è¦æå–çš„å¸§
    frame_interval = int(fps * interval)
    if frame_interval < 1:
        frame_interval = 1

    frames_dir = output_dir / "original_frames"
    frames_dir.mkdir(exist_ok=True)

    frame_paths = []
    frame_idx = 0
    extracted_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_idx % frame_interval == 0:
            frame_path = frames_dir / f"frame_{extracted_count:06d}.png"
            cv2.imwrite(str(frame_path), frame)
            frame_paths.append(str(frame_path))
            extracted_count += 1

        frame_idx += 1

    cap.release()

    return frame_paths, fps, (width, height)


def extract_audio(video_path: str, output_dir: Path) -> str | None:
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    try:
        from moviepy import VideoFileClip

        audio_path = output_dir / "audio.mp3"
        video = VideoFileClip(video_path)

        if video.audio is not None:
            video.audio.write_audiofile(str(audio_path), logger=None)
            video.close()
            return str(audio_path)

        video.close()
        return None
    except Exception as e:
        print(f"æå–éŸ³é¢‘å¤±è´¥: {e}")
        return None


def call_qwen_image_edit(
    image_path: str,
    prompt: str,
    api_key: str,
    output_path: str,
    size: str | None = None,
) -> str:
    """
    è°ƒç”¨Qwen Image Edit APIç¼–è¾‘å›¾ç‰‡

    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        size: è¾“å‡ºå°ºå¯¸ (å¦‚ "1024*1024")

    Returns:
        è¾“å‡ºå›¾ç‰‡è·¯å¾„
    """
    import dashscope
    from dashscope import MultiModalConversation
    import requests

    dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'

    # ç¼–ç å›¾ç‰‡
    image_base64 = encode_image_to_base64(image_path)

    messages = [
        {
            "role": "user",
            "content": [
                {"image": image_base64},
                {"text": prompt}
            ]
        }
    ]

    # æ„å»ºè¯·æ±‚å‚æ•°
    kwargs = {
        "api_key": api_key,
        "model": "qwen-image-edit-plus",
        "messages": messages,
        "stream": False,
        "n": 1,
        "watermark": False,
        "prompt_extend": True,
    }

    if size:
        kwargs["size"] = size

    response = MultiModalConversation.call(**kwargs)

    if response.status_code == 200:
        # è·å–ç”Ÿæˆçš„å›¾ç‰‡URL
        image_url = response.output.choices[0].message.content[0]['image']

        # ä¸‹è½½å›¾ç‰‡
        img_response = requests.get(image_url)
        if img_response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(img_response.content)
            return output_path
        else:
            raise Exception(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: HTTP {img_response.status_code}")
    else:
        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")


def process_frames_parallel(
    frame_paths: list[str],
    prompt: str,
    api_key: str,
    output_dir: Path,
    size: str | None = None,
    max_workers: int = 3,
    progress_callback=None,
) -> list[str]:
    """
    å¹¶è¡Œå¤„ç†å¤šä¸ªå¸§

    Args:
        frame_paths: åŸå§‹å¸§è·¯å¾„åˆ—è¡¨
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        output_dir: è¾“å‡ºç›®å½•
        size: è¾“å‡ºå°ºå¯¸
        max_workers: æœ€å¤§å¹¶è¡Œæ•°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

    Returns:
        ç¼–è¾‘åçš„å¸§è·¯å¾„åˆ—è¡¨
    """
    edited_dir = output_dir / "edited_frames"
    edited_dir.mkdir(exist_ok=True)

    edited_paths = [None] * len(frame_paths)
    completed = 0
    total = len(frame_paths)

    def process_single(args):
        idx, frame_path = args
        output_path = str(edited_dir / f"edited_{idx:06d}.png")
        try:
            result = call_qwen_image_edit(frame_path, prompt, api_key, output_path, size)
            return idx, result, None
        except Exception as e:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾
            shutil.copy(frame_path, output_path)
            return idx, output_path, str(e)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(process_single, (i, path)): i
                   for i, path in enumerate(frame_paths)}

        for future in as_completed(futures):
            idx, result_path, error = future.result()
            edited_paths[idx] = result_path
            completed += 1

            if error:
                print(f"å¸§ {idx} å¤„ç†å‡ºé”™: {error}")

            if progress_callback:
                progress_callback(completed / total, f"å·²å¤„ç† {completed}/{total} å¸§")

    return edited_paths


def create_video_from_frames(
    frame_paths: list[str],
    output_path: str,
    fps: float,
    audio_path: str | None = None,
) -> str:
    """
    ä»å¸§åºåˆ—åˆ›å»ºè§†é¢‘

    Args:
        frame_paths: å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        fps: å¸§ç‡
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰

    Returns:
        è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    from moviepy import ImageSequenceClip, AudioFileClip

    # åˆ›å»ºè§†é¢‘
    clip = ImageSequenceClip(frame_paths, fps=fps)

    # æ·»åŠ éŸ³é¢‘
    if audio_path and os.path.exists(audio_path):
        audio = AudioFileClip(audio_path)
        # ç¡®ä¿éŸ³é¢‘é•¿åº¦ä¸è§†é¢‘åŒ¹é…
        if audio.duration > clip.duration:
            audio = audio.subclipped(0, clip.duration)
        clip = clip.with_audio(audio)

    # è¾“å‡ºè§†é¢‘
    clip.write_videofile(
        output_path,
        codec='libx264',
        audio_codec='aac',
        logger=None,
    )

    clip.close()
    if audio_path and os.path.exists(audio_path):
        audio.close()

    return output_path


def process_video(
    video_path: str,
    interval: float,
    prompt: str,
    api_key: str,
    output_size: str,
    max_workers: int,
    progress=gr.Progress(),
) -> tuple[str, list[tuple[str, str]], str]:
    """
    å¤„ç†è§†é¢‘çš„ä¸»å‡½æ•°

    Returns:
        (è¾“å‡ºè§†é¢‘è·¯å¾„, é¢„è§ˆå›¾ç‰‡åˆ—è¡¨, çŠ¶æ€æ¶ˆæ¯)
    """
    if not video_path:
        return None, [], "è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶"

    if not api_key:
        return None, [], "è¯·è¾“å…¥API Key"

    if not prompt:
        return None, [], "è¯·è¾“å…¥ç¼–è¾‘æŒ‡ä»¤"

    # åˆ›å»ºå·¥ä½œç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    work_dir = DEFAULT_OUTPUT_DIR / f"job_{timestamp}"
    work_dir.mkdir(parents=True, exist_ok=True)

    try:
        # æ­¥éª¤1: æå–å¸§
        progress(0.1, desc="æ­£åœ¨æå–è§†é¢‘å¸§...")
        frame_paths, fps, (width, height) = extract_frames(video_path, interval, work_dir)

        if not frame_paths:
            return None, [], "æ— æ³•ä»è§†é¢‘ä¸­æå–å¸§"

        progress(0.15, desc=f"å·²æå– {len(frame_paths)} å¸§")

        # æ­¥éª¤2: æå–éŸ³é¢‘
        progress(0.2, desc="æ­£åœ¨æå–éŸ³é¢‘...")
        audio_path = extract_audio(video_path, work_dir)

        # æ­¥éª¤3: å¤„ç†å¸§
        progress(0.25, desc="æ­£åœ¨å¤„ç†å¸§...")

        # è§£æè¾“å‡ºå°ºå¯¸
        size = output_size if output_size and output_size != "åŸå§‹å°ºå¯¸" else None

        def update_progress(ratio, msg):
            # å¸§å¤„ç†å 25%-85%çš„è¿›åº¦
            progress(0.25 + ratio * 0.6, desc=msg)

        edited_paths = process_frames_parallel(
            frame_paths,
            prompt,
            api_key,
            work_dir,
            size=size,
            max_workers=max_workers,
            progress_callback=update_progress,
        )

        # æ­¥éª¤4: ç”Ÿæˆè§†é¢‘
        progress(0.9, desc="æ­£åœ¨åˆæˆè§†é¢‘...")
        output_video_path = str(work_dir / "output.mp4")
        create_video_from_frames(edited_paths, output_video_path, fps, audio_path)

        progress(1.0, desc="å¤„ç†å®Œæˆ!")

        # å‡†å¤‡é¢„è§ˆå›¾ç‰‡ï¼ˆæ˜¾ç¤ºåŸå›¾å’Œç¼–è¾‘åçš„å¯¹æ¯”ï¼‰
        preview_images = []
        step = max(1, len(frame_paths) // 6)  # æœ€å¤šæ˜¾ç¤º6ç»„å¯¹æ¯”
        for i in range(0, len(frame_paths), step):
            if i < len(edited_paths) and edited_paths[i]:
                preview_images.append((frame_paths[i], f"åŸå§‹å¸§ {i+1}"))
                preview_images.append((edited_paths[i], f"ç¼–è¾‘å {i+1}"))

        status = f"å¤„ç†å®Œæˆ! å…±å¤„ç† {len(frame_paths)} å¸§ï¼Œè¾“å‡ºè§†é¢‘: {output_video_path}"
        return output_video_path, preview_images, status

    except Exception as e:
        return None, [], f"å¤„ç†å¤±è´¥: {str(e)}"


def create_ui():
    """åˆ›å»ºGradioç•Œé¢"""

    with gr.Blocks(title="è§†é¢‘é£æ ¼ç¼–è¾‘å™¨", theme=gr.themes.Soft()) as app:
        gr.Markdown("""
        # ğŸ¬ è§†é¢‘é£æ ¼ç¼–è¾‘å™¨

        ä½¿ç”¨é€šä¹‰åƒé—® Qwen Image Edit API å¯¹è§†é¢‘è¿›è¡Œé£æ ¼è½¬æ¢ã€‚
        ä¸Šä¼ è§†é¢‘åï¼Œä¼šæŒ‰æŒ‡å®šæ—¶é—´é—´éš”æå–å¸§ï¼Œä½¿ç”¨AIç¼–è¾‘æ¯ä¸€å¸§ï¼Œç„¶åé‡æ–°åˆæˆè§†é¢‘ã€‚
        """)

        with gr.Row():
            with gr.Column(scale=1):
                # è¾“å…¥åŒºåŸŸ
                gr.Markdown("### ğŸ“ è¾“å…¥è®¾ç½®")

                video_input = gr.Video(
                    label="ä¸Šä¼ è§†é¢‘",
                    sources=["upload"],
                )

                api_key_input = gr.Textbox(
                    label="DashScope API Key",
                    placeholder="è¯·è¾“å…¥æ‚¨çš„API Key",
                    type="password",
                    value=os.getenv("DASHSCOPE_API_KEY", ""),
                )

                prompt_input = gr.Textbox(
                    label="ç¼–è¾‘æŒ‡ä»¤",
                    placeholder="æè¿°æ‚¨æƒ³è¦çš„è§†è§’/æ™¯åˆ«å˜åŒ–ï¼Œä¾‹å¦‚ï¼šå°†ç”»é¢è½¬æ¢ä¸ºä¿¯è§†è§’åº¦ï¼Œå¢åŠ æ™¯æ·±æ•ˆæœ",
                    lines=3,
                    value="å°†ç”»é¢è½¬æ¢ä¸ºç”µå½±çº§åˆ«çš„å¹¿è§’é•œå¤´æ•ˆæœï¼Œå¢å¼ºæ™¯æ·±å’Œç©ºé—´æ„Ÿ",
                )

                with gr.Row():
                    interval_input = gr.Slider(
                        label="å¸§æå–é—´éš”ï¼ˆç§’ï¼‰",
                        minimum=0.1,
                        maximum=5.0,
                        value=1.0,
                        step=0.1,
                        info="é—´éš”è¶Šå°ï¼Œå¸§æ•°è¶Šå¤šï¼Œå¤„ç†æ—¶é—´è¶Šé•¿",
                    )

                    workers_input = gr.Slider(
                        label="å¹¶è¡Œå¤„ç†æ•°",
                        minimum=1,
                        maximum=5,
                        value=3,
                        step=1,
                        info="åŒæ—¶å¤„ç†çš„å¸§æ•°ï¼Œå»ºè®®2-3",
                    )

                size_input = gr.Dropdown(
                    label="è¾“å‡ºå°ºå¯¸",
                    choices=["åŸå§‹å°ºå¯¸", "512*512", "768*768", "1024*1024", "1024*768", "768*1024"],
                    value="åŸå§‹å°ºå¯¸",
                    info="è®¾ç½®ç¼–è¾‘åå›¾ç‰‡çš„åˆ†è¾¨ç‡",
                )

                process_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary", size="lg")

            with gr.Column(scale=1):
                # è¾“å‡ºåŒºåŸŸ
                gr.Markdown("### ğŸ“º è¾“å‡ºç»“æœ")

                status_output = gr.Textbox(
                    label="å¤„ç†çŠ¶æ€",
                    interactive=False,
                )

                video_output = gr.Video(
                    label="è¾“å‡ºè§†é¢‘",
                )

        # é¢„è§ˆåŒºåŸŸ
        gr.Markdown("### ğŸ–¼ï¸ å¸§é¢„è§ˆï¼ˆåŸå›¾ vs ç¼–è¾‘åï¼‰")
        preview_gallery = gr.Gallery(
            label="å¸§å¯¹æ¯”é¢„è§ˆ",
            columns=4,
            rows=2,
            height="auto",
            object_fit="contain",
        )

        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ## ä½¿ç”¨æ­¥éª¤

            1. **è·å–API Key**: å‰å¾€ [é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°](https://bailian.console.alibabacloud.com/) æ³¨å†Œå¹¶è·å– DashScope API Key
            2. **ä¸Šä¼ è§†é¢‘**: æ”¯æŒå¸¸è§è§†é¢‘æ ¼å¼ï¼ˆMP4, AVI, MOVç­‰ï¼‰
            3. **è®¾ç½®å‚æ•°**:
               - **å¸§æå–é—´éš”**: å»ºè®®0.5-2ç§’ï¼Œé—´éš”è¶Šå°æ•ˆæœè¶Šæµç•…ä½†å¤„ç†æ—¶é—´è¶Šé•¿
               - **ç¼–è¾‘æŒ‡ä»¤**: æè¿°æ‚¨æƒ³è¦çš„è§†è§‰æ•ˆæœå˜åŒ–
               - **å¹¶è¡Œå¤„ç†æ•°**: å»ºè®®2-3ï¼Œè¿‡é«˜å¯èƒ½è§¦å‘APIé™æµ
            4. **å¼€å§‹å¤„ç†**: ç‚¹å‡»æŒ‰é’®åç­‰å¾…å¤„ç†å®Œæˆ
            5. **æŸ¥çœ‹ç»“æœ**: é¢„è§ˆç¼–è¾‘åçš„å¸§å¹¶ä¸‹è½½è¾“å‡ºè§†é¢‘

            ## ç¼–è¾‘æŒ‡ä»¤ç¤ºä¾‹

            - å°†ç”»é¢è½¬æ¢ä¸ºä¿¯è§†è§’åº¦
            - å¢åŠ ç”µå½±çº§åˆ«çš„æ™¯æ·±æ•ˆæœ
            - è½¬æ¢ä¸ºå¹¿è§’é•œå¤´è§†è§’
            - å¢å¼ºç”»é¢çš„ç©ºé—´å±‚æ¬¡æ„Ÿ
            - å°†è¿‘æ™¯è½¬æ¢ä¸ºä¸­æ™¯æ„å›¾
            - æ·»åŠ æŸ”å’Œçš„èƒŒæ™¯è™šåŒ–æ•ˆæœ

            ## æ³¨æ„äº‹é¡¹

            - è§†é¢‘è¾ƒé•¿æ—¶å¤„ç†æ—¶é—´å¯èƒ½è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…
            - APIè°ƒç”¨ä¼šäº§ç”Ÿè´¹ç”¨ï¼Œè¯·æ³¨æ„æ§åˆ¶å¸§æ•°
            - å»ºè®®å…ˆç”¨çŸ­è§†é¢‘æµ‹è¯•æ•ˆæœ
            """)

        # ç»‘å®šäº‹ä»¶
        process_btn.click(
            fn=process_video,
            inputs=[
                video_input,
                interval_input,
                prompt_input,
                api_key_input,
                size_input,
                workers_input,
            ],
            outputs=[video_output, preview_gallery, status_output],
            show_progress=True,
        )

    return app


def main():
    """ä¸»å‡½æ•°"""
    app = create_ui()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
    )


if __name__ == "__main__":
    main()
