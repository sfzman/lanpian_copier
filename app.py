"""
Video Style Editor - ä½¿ç”¨Qwen Image Edit APIè¿›è¡Œè§†é¢‘é£æ ¼ç¼–è¾‘
"""

import os
import base64
import mimetypes
import tempfile
import shutil
import json
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

import random
import cv2
import numpy as np
from PIL import Image
import gradio as gr
from dotenv import load_dotenv
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é»˜è®¤è¾“å‡ºç›®å½•
DEFAULT_OUTPUT_DIR = Path("./output")
DEFAULT_OUTPUT_DIR.mkdir(exist_ok=True)


# ==================== ä»»åŠ¡é…ç½®ç®¡ç† ====================

def save_job_config(
    job_dir: Path,
    video_path: str,
    interval: float,
    prompt: str,
    output_size: str,
    max_workers: int,
    pan_range: float,
    fps: float,
    width: int,
    height: int,
    total_frames: int,
    has_audio: bool,
):
    """
    ä¿å­˜ä»»åŠ¡é…ç½®åˆ° job_config.json

    Args:
        job_dir: ä»»åŠ¡ç›®å½•
        video_path: åŸå§‹è§†é¢‘è·¯å¾„
        interval: å¸§æå–é—´éš”ï¼ˆç§’ï¼‰
        prompt: ç¼–è¾‘æŒ‡ä»¤
        output_size: è¾“å‡ºå°ºå¯¸
        max_workers: å¹¶è¡Œå¤„ç†æ•°
        pan_range: å¹³ç§»åŠ¨æ•ˆèŒƒå›´ï¼ˆç™¾åˆ†æ¯”ï¼‰
        fps: è§†é¢‘å¸§ç‡
        width: è§†é¢‘å®½åº¦
        height: è§†é¢‘é«˜åº¦
        total_frames: æå–çš„æ€»å¸§æ•°
        has_audio: æ˜¯å¦æœ‰éŸ³é¢‘
    """
    config = {
        "video_path": video_path,
        "interval": interval,
        "prompt": prompt,
        "output_size": output_size,
        "max_workers": max_workers,
        "pan_range": pan_range,
        "fps": fps,
        "width": width,
        "height": height,
        "total_frames": total_frames,
        "has_audio": has_audio,
        "created_at": datetime.now().isoformat(),
    }
    config_path = job_dir / "job_config.json"
    with open(config_path, "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    logger.info(f"ä»»åŠ¡é…ç½®å·²ä¿å­˜: {config_path}")


def load_job_config(job_dir: Path) -> dict | None:
    """
    åŠ è½½ä»»åŠ¡é…ç½®

    Args:
        job_dir: ä»»åŠ¡ç›®å½•

    Returns:
        é…ç½®å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
    """
    config_path = job_dir / "job_config.json"
    if not config_path.exists():
        logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return None

    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
    logger.info(f"å·²åŠ è½½ä»»åŠ¡é…ç½®: {config_path}")
    return config


# ==================== å®Œæ•´æ€§æ£€æŸ¥å‡½æ•° ====================

def check_original_frames(job_dir: Path, expected_count: int) -> list[int]:
    """
    æ£€æŸ¥åŸå§‹å¸§æ˜¯å¦å®Œæ•´

    Args:
        job_dir: ä»»åŠ¡ç›®å½•
        expected_count: é¢„æœŸçš„å¸§æ•°

    Returns:
        ç¼ºå¤±çš„å¸§ç´¢å¼•åˆ—è¡¨
    """
    frames_dir = job_dir / "original_frames"
    if not frames_dir.exists():
        return list(range(expected_count))

    missing = []
    for i in range(expected_count):
        frame_path = frames_dir / f"frame_{i:06d}.png"
        if not frame_path.exists():
            missing.append(i)

    return missing


def check_edited_frames(job_dir: Path, expected_count: int) -> list[int]:
    """
    æ£€æŸ¥ç¼–è¾‘å¸§æ˜¯å¦å®Œæ•´

    Args:
        job_dir: ä»»åŠ¡ç›®å½•
        expected_count: é¢„æœŸçš„å¸§æ•°

    Returns:
        ç¼ºå¤±çš„å¸§ç´¢å¼•åˆ—è¡¨
    """
    edited_dir = job_dir / "edited_frames"
    if not edited_dir.exists():
        return list(range(expected_count))

    missing = []
    for i in range(expected_count):
        edited_path = edited_dir / f"edited_{i:06d}.png"
        if not edited_path.exists():
            missing.append(i)

    return missing


def check_audio(job_dir: Path) -> bool:
    """æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    audio_path = job_dir / "audio.mp3"
    return audio_path.exists()


def check_output_video(job_dir: Path) -> bool:
    """æ£€æŸ¥è¾“å‡ºè§†é¢‘æ˜¯å¦å­˜åœ¨"""
    video_path = job_dir / "output.mp4"
    return video_path.exists()


# ==================== è¡¥å…¨å‡½æ•° ====================

def extract_missing_frames(
    video_path: str,
    interval: float,
    job_dir: Path,
    missing_indices: list[int],
) -> list[str]:
    """
    åªæå–ç¼ºå¤±çš„å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        interval: æå–é—´éš”ï¼ˆç§’ï¼‰
        job_dir: ä»»åŠ¡ç›®å½•
        missing_indices: ç¼ºå¤±çš„å¸§ç´¢å¼•åˆ—è¡¨

    Returns:
        æå–çš„å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    if not missing_indices:
        return []

    logger.info(f"å¼€å§‹è¡¥å…¨ç¼ºå¤±å¸§: å…± {len(missing_indices)} å¸§")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_interval = int(fps * interval)
    if frame_interval < 1:
        frame_interval = 1

    frames_dir = job_dir / "original_frames"
    frames_dir.mkdir(exist_ok=True)

    missing_set = set(missing_indices)
    extracted_paths = []
    frame_idx = 0
    extracted_idx = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_idx % frame_interval == 0:
            if extracted_idx in missing_set:
                frame_path = frames_dir / f"frame_{extracted_idx:06d}.png"
                cv2.imwrite(str(frame_path), frame)
                extracted_paths.append(str(frame_path))
                logger.debug(f"å·²è¡¥å…¨å¸§: {frame_path}")
            extracted_idx += 1

        frame_idx += 1

    cap.release()
    logger.info(f"å¸§è¡¥å…¨å®Œæˆ: å·²è¡¥å…¨ {len(extracted_paths)} å¸§")
    return extracted_paths


def process_missing_edited_frames(
    job_dir: Path,
    missing_indices: list[int],
    prompt: str,
    api_key: str,
    size: str | None = None,
    max_workers: int = 2,
    progress_callback=None,
) -> list[str]:
    """
    åªå¤„ç†ç¼ºå¤±çš„ç¼–è¾‘å¸§

    Args:
        job_dir: ä»»åŠ¡ç›®å½•
        missing_indices: ç¼ºå¤±çš„å¸§ç´¢å¼•åˆ—è¡¨
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        size: è¾“å‡ºå°ºå¯¸
        max_workers: æœ€å¤§å¹¶è¡Œæ•°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

    Returns:
        ç¼–è¾‘åçš„å¸§è·¯å¾„åˆ—è¡¨
    """
    if not missing_indices:
        return []

    logger.info(f"å¼€å§‹è¡¥å…¨ç¼ºå¤±çš„ç¼–è¾‘å¸§: å…± {len(missing_indices)} å¸§")

    frames_dir = job_dir / "original_frames"
    edited_dir = job_dir / "edited_frames"
    edited_dir.mkdir(exist_ok=True)

    edited_paths = []
    completed = 0
    total = len(missing_indices)

    def process_single(idx):
        frame_path = str(frames_dir / f"frame_{idx:06d}.png")
        output_path = str(edited_dir / f"edited_{idx:06d}.png")

        if not os.path.exists(frame_path):
            logger.warning(f"åŸå§‹å¸§ä¸å­˜åœ¨: {frame_path}")
            return idx, None, "åŸå§‹å¸§ä¸å­˜åœ¨"

        try:
            result = call_qwen_image_edit(frame_path, prompt, api_key, output_path, size)
            return idx, result, None
        except Exception as e:
            # å¦‚æœ API è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾
            shutil.copy(frame_path, output_path)
            return idx, output_path, str(e)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(process_single, idx): idx for idx in missing_indices}

        for future in as_completed(futures):
            idx, result_path, error = future.result()
            if result_path:
                edited_paths.append(result_path)
            completed += 1

            if error:
                logger.warning(f"å¸§ {idx} å¤„ç†å‡ºé”™: {error}")
            else:
                logger.info(f"å¸§ {idx} å¤„ç†å®Œæˆ ({completed}/{total})")

            if progress_callback:
                progress_callback(completed / total, f"å·²å¤„ç† {completed}/{total} å¸§")

    logger.info(f"ç¼–è¾‘å¸§è¡¥å…¨å®Œæˆ: {len(edited_paths)}/{total}")
    return edited_paths


# ==================== é‡åšä»»åŠ¡ä¸»å‡½æ•° ====================

def retry_job(
    job_folder: str,
    api_key: str,
    prompt_override: str = None,
    max_workers: int = 2,
    regenerate_video: bool = True,
    progress=gr.Progress(),
) -> tuple[str, list[tuple[str, str]], str]:
    """
    é‡åšä»»åŠ¡ï¼šæ£€æŸ¥å¹¶è¡¥å…¨ç¼ºå¤±çš„éƒ¨åˆ†

    Args:
        job_folder: job æ–‡ä»¶å¤¹åï¼ˆå¦‚ "job_20260116_203414"ï¼‰
        api_key: APIå¯†é’¥
        prompt_override: è¦†ç›–åŸæœ‰çš„ promptï¼ˆå¯é€‰ï¼‰
        max_workers: å¹¶è¡Œå¤„ç†æ•°
        regenerate_video: æ˜¯å¦é‡æ–°ç”Ÿæˆè§†é¢‘
        progress: è¿›åº¦å›è°ƒ

    Returns:
        (è¾“å‡ºè§†é¢‘è·¯å¾„, é¢„è§ˆå›¾ç‰‡åˆ—è¡¨, çŠ¶æ€æ¶ˆæ¯)
    """
    if not job_folder:
        return None, [], "è¯·è¾“å…¥ job æ–‡ä»¶å¤¹å"

    if not api_key:
        return None, [], "è¯·è¾“å…¥ API Key"

    # æŸ¥æ‰¾ job ç›®å½•
    job_dir = DEFAULT_OUTPUT_DIR / job_folder
    if not job_dir.exists():
        return None, [], f"ä»»åŠ¡ç›®å½•ä¸å­˜åœ¨: {job_dir}"

    logger.info(f"========== å¼€å§‹é‡åšä»»åŠ¡ ==========")
    logger.info(f"ä»»åŠ¡ç›®å½•: {job_dir}")

    # åŠ è½½é…ç½®
    config = load_job_config(job_dir)
    if not config:
        return None, [], "æ— æ³•åŠ è½½ä»»åŠ¡é…ç½®ï¼Œè¯·ç¡®ä¿è¯¥ä»»åŠ¡åŒ…å« job_config.json æ–‡ä»¶"

    video_path = config["video_path"]
    interval = config["interval"]
    prompt = prompt_override if prompt_override else config["prompt"]
    output_size = config["output_size"]
    pan_range = config["pan_range"]
    total_frames = config["total_frames"]
    has_audio = config.get("has_audio", False)

    size = output_size if output_size and output_size != "åŸå§‹å°ºå¯¸" else None
    pan_range_ratio = pan_range / 100.0

    logger.info(f"åŸå§‹è§†é¢‘: {video_path}")
    logger.info(f"é¢„æœŸå¸§æ•°: {total_frames}")
    logger.info(f"ç¼–è¾‘æŒ‡ä»¤: {prompt[:50]}...")

    status_messages = []

    try:
        # æ­¥éª¤1: æ£€æŸ¥åŸå§‹å¸§å®Œæ•´æ€§
        progress(0.05, desc="æ£€æŸ¥åŸå§‹å¸§å®Œæ•´æ€§...")
        missing_original = check_original_frames(job_dir, total_frames)

        if missing_original:
            logger.info(f"å‘ç° {len(missing_original)} ä¸ªç¼ºå¤±çš„åŸå§‹å¸§ï¼Œå¼€å§‹è¡¥å…¨...")
            status_messages.append(f"åŸå§‹å¸§ç¼ºå¤± {len(missing_original)} ä¸ªï¼Œæ­£åœ¨è¡¥å…¨")

            if not os.path.exists(video_path):
                return None, [], f"åŸå§‹è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}ï¼Œæ— æ³•è¡¥å…¨åŸå§‹å¸§"

            progress(0.1, desc=f"æ­£åœ¨è¡¥å…¨ {len(missing_original)} ä¸ªåŸå§‹å¸§...")
            extract_missing_frames(video_path, interval, job_dir, missing_original)
        else:
            status_messages.append("åŸå§‹å¸§å®Œæ•´ âœ“")
            logger.info("åŸå§‹å¸§å®Œæ•´")

        progress(0.15, desc="æ£€æŸ¥ç¼–è¾‘å¸§å®Œæ•´æ€§...")

        # æ­¥éª¤2: æ£€æŸ¥ç¼–è¾‘å¸§å®Œæ•´æ€§
        missing_edited = check_edited_frames(job_dir, total_frames)

        if missing_edited:
            logger.info(f"å‘ç° {len(missing_edited)} ä¸ªç¼ºå¤±çš„ç¼–è¾‘å¸§ï¼Œå¼€å§‹è¡¥å…¨...")
            status_messages.append(f"ç¼–è¾‘å¸§ç¼ºå¤± {len(missing_edited)} ä¸ªï¼Œæ­£åœ¨è¡¥å…¨")

            def update_progress(ratio, msg):
                progress(0.2 + ratio * 0.5, desc=msg)

            progress(0.2, desc=f"æ­£åœ¨å¤„ç† {len(missing_edited)} ä¸ªç¼ºå¤±çš„ç¼–è¾‘å¸§...")
            process_missing_edited_frames(
                job_dir,
                missing_edited,
                prompt,
                api_key,
                size=size,
                max_workers=max_workers,
                progress_callback=update_progress,
            )
        else:
            status_messages.append("ç¼–è¾‘å¸§å®Œæ•´ âœ“")
            logger.info("ç¼–è¾‘å¸§å®Œæ•´")

        progress(0.75, desc="æ£€æŸ¥éŸ³é¢‘...")

        # æ­¥éª¤3: æ£€æŸ¥éŸ³é¢‘
        if has_audio and not check_audio(job_dir):
            logger.info("éŸ³é¢‘æ–‡ä»¶ç¼ºå¤±ï¼Œæ­£åœ¨é‡æ–°æå–...")
            status_messages.append("éŸ³é¢‘ç¼ºå¤±ï¼Œæ­£åœ¨é‡æ–°æå–")

            if os.path.exists(video_path):
                extract_audio(video_path, job_dir)
            else:
                status_messages.append("è­¦å‘Šï¼šåŸå§‹è§†é¢‘ä¸å­˜åœ¨ï¼Œæ— æ³•æå–éŸ³é¢‘")
        else:
            if has_audio:
                status_messages.append("éŸ³é¢‘å®Œæ•´ âœ“")
            else:
                status_messages.append("åŸå§‹è§†é¢‘æ— éŸ³é¢‘")

        # æ­¥éª¤4: æ£€æŸ¥å¹¶é‡æ–°ç”Ÿæˆè§†é¢‘
        progress(0.8, desc="æ£€æŸ¥è¾“å‡ºè§†é¢‘...")

        video_exists = check_output_video(job_dir)
        need_regenerate = regenerate_video or not video_exists or missing_edited

        if need_regenerate:
            logger.info("æ­£åœ¨é‡æ–°åˆæˆè§†é¢‘...")
            status_messages.append("æ­£åœ¨é‡æ–°åˆæˆè§†é¢‘")

            progress(0.85, desc="æ­£åœ¨åˆæˆè§†é¢‘...")

            # æ”¶é›†æ‰€æœ‰ç¼–è¾‘åçš„å¸§
            edited_dir = job_dir / "edited_frames"
            edited_paths = []
            for i in range(total_frames):
                edited_path = edited_dir / f"edited_{i:06d}.png"
                if edited_path.exists():
                    edited_paths.append(str(edited_path))
                else:
                    # å¦‚æœç¼–è¾‘å¸§ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹å¸§
                    original_path = job_dir / "original_frames" / f"frame_{i:06d}.png"
                    if original_path.exists():
                        edited_paths.append(str(original_path))

            if not edited_paths:
                return None, [], "æ²¡æœ‰å¯ç”¨çš„å¸§æ¥ç”Ÿæˆè§†é¢‘"

            output_video_path = str(job_dir / "output.mp4")
            audio_path = str(job_dir / "audio.mp3") if check_audio(job_dir) else None

            output_fps = 24.0
            create_video_from_frames(
                edited_paths,
                output_video_path,
                output_fps,
                interval,
                audio_path,
                pan_range_ratio,
            )
            status_messages.append("è§†é¢‘åˆæˆå®Œæˆ âœ“")
        else:
            status_messages.append("è¾“å‡ºè§†é¢‘å·²å­˜åœ¨ âœ“")

        progress(1.0, desc="é‡åšå®Œæˆ!")

        # å‡†å¤‡é¢„è§ˆå›¾ç‰‡
        output_video_path = str(job_dir / "output.mp4")
        preview_images = []
        frames_dir = job_dir / "original_frames"
        edited_dir = job_dir / "edited_frames"

        step = max(1, total_frames // 6)
        for i in range(0, total_frames, step):
            original_path = frames_dir / f"frame_{i:06d}.png"
            edited_path = edited_dir / f"edited_{i:06d}.png"

            if original_path.exists():
                preview_images.append((str(original_path), f"åŸå§‹å¸§ {i+1}"))
            if edited_path.exists():
                preview_images.append((str(edited_path), f"ç¼–è¾‘å {i+1}"))

        status = "é‡åšå®Œæˆ! " + " | ".join(status_messages)
        logger.info(f"========== é‡åšä»»åŠ¡å®Œæˆ ==========")
        return output_video_path, preview_images, status

    except Exception as e:
        logger.error(f"é‡åšä»»åŠ¡å¤±è´¥: {str(e)}", exc_info=True)
        return None, [], f"é‡åšä»»åŠ¡å¤±è´¥: {str(e)}"


def check_job_status(job_folder: str) -> str:
    """
    æ£€æŸ¥ä»»åŠ¡çŠ¶æ€

    Args:
        job_folder: job æ–‡ä»¶å¤¹å

    Returns:
        çŠ¶æ€æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    if not job_folder:
        return "è¯·è¾“å…¥ job æ–‡ä»¶å¤¹å"

    job_dir = DEFAULT_OUTPUT_DIR / job_folder
    if not job_dir.exists():
        return f"ä»»åŠ¡ç›®å½•ä¸å­˜åœ¨: {job_dir}"

    config = load_job_config(job_dir)
    if not config:
        return "æ— æ³•åŠ è½½ä»»åŠ¡é…ç½®ï¼Œè¯¥ç›®å½•å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ä»»åŠ¡ç›®å½•"

    total_frames = config["total_frames"]
    has_audio = config.get("has_audio", False)

    # æ£€æŸ¥å„éƒ¨åˆ†å®Œæ•´æ€§
    missing_original = check_original_frames(job_dir, total_frames)
    missing_edited = check_edited_frames(job_dir, total_frames)
    audio_ok = check_audio(job_dir) if has_audio else True
    video_ok = check_output_video(job_dir)

    lines = [
        f"ğŸ“ ä»»åŠ¡ç›®å½•: {job_folder}",
        f"ğŸ¬ åŸå§‹è§†é¢‘: {config['video_path']}",
        f"ğŸ“ ç¼–è¾‘æŒ‡ä»¤: {config['prompt'][:80]}...",
        f"â±ï¸ å¸§æå–é—´éš”: {config['interval']}ç§’",
        f"ğŸ“ è¾“å‡ºå°ºå¯¸: {config['output_size']}",
        f"ğŸ”„ å¹³ç§»åŠ¨æ•ˆ: {config['pan_range']}%",
        "",
        "=== å®Œæ•´æ€§æ£€æŸ¥ ===",
        f"ğŸ–¼ï¸ åŸå§‹å¸§: {total_frames - len(missing_original)}/{total_frames} " +
        ("âœ“ å®Œæ•´" if not missing_original else f"âŒ ç¼ºå¤± {len(missing_original)} å¸§"),
        f"ğŸ¨ ç¼–è¾‘å¸§: {total_frames - len(missing_edited)}/{total_frames} " +
        ("âœ“ å®Œæ•´" if not missing_edited else f"âŒ ç¼ºå¤± {len(missing_edited)} å¸§"),
        f"ğŸ”Š éŸ³é¢‘: {'âœ“ å­˜åœ¨' if audio_ok else 'âŒ ç¼ºå¤±'}" if has_audio else "ğŸ”Š éŸ³é¢‘: åŸå§‹è§†é¢‘æ— éŸ³é¢‘",
        f"ğŸ¥ è¾“å‡ºè§†é¢‘: {'âœ“ å­˜åœ¨' if video_ok else 'âŒ ä¸å­˜åœ¨'}",
    ]

    if missing_edited:
        lines.append("")
        lines.append(f"ç¼ºå¤±çš„ç¼–è¾‘å¸§ç´¢å¼•: {missing_edited[:20]}{'...' if len(missing_edited) > 20 else ''}")

    return "\n".join(lines)


def encode_image_to_base64(image_path: str) -> str:
    """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64æ ¼å¼"""
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith("image/"):
        mime_type = "image/png"

    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
    return f"data:{mime_type};base64,{encoded_string}"


def extract_frames(video_path: str, interval: float, output_dir: Path) -> tuple[list[str], float, tuple[int, int]]:
    """
    ä»è§†é¢‘ä¸­æŒ‰æŒ‡å®šæ—¶é—´é—´éš”æå–å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        interval: æå–é—´éš”ï¼ˆç§’ï¼‰
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        (å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨, fps, (å®½åº¦, é«˜åº¦))
    """
    logger.info(f"å¼€å§‹æå–å¸§: {video_path}, é—´éš”: {interval}ç§’")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    logger.info(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.2f}fps, æ€»å¸§æ•°: {total_frames}, æ—¶é•¿: {duration:.2f}ç§’")

    # è®¡ç®—è¦æå–çš„å¸§
    frame_interval = int(fps * interval)
    if frame_interval < 1:
        frame_interval = 1

    frames_dir = output_dir / "original_frames"
    frames_dir.mkdir(exist_ok=True)

    frame_paths = []
    frame_idx = 0
    extracted_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_idx % frame_interval == 0:
            frame_path = frames_dir / f"frame_{extracted_count:06d}.png"
            cv2.imwrite(str(frame_path), frame)
            frame_paths.append(str(frame_path))
            extracted_count += 1

        frame_idx += 1

    cap.release()
    logger.info(f"å¸§æå–å®Œæˆ: å…±æå– {extracted_count} å¸§")

    return frame_paths, fps, (width, height)


def extract_audio(video_path: str, output_dir: Path) -> str | None:
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    logger.info(f"å¼€å§‹æå–éŸ³é¢‘: {video_path}")
    try:
        from moviepy import VideoFileClip

        audio_path = output_dir / "audio.mp3"
        video = VideoFileClip(video_path)

        if video.audio is not None:
            logger.info("æ£€æµ‹åˆ°éŸ³é¢‘è½¨é“ï¼Œæ­£åœ¨æå–...")
            video.audio.write_audiofile(str(audio_path), logger=None)
            video.close()
            logger.info(f"éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
            return str(audio_path)

        video.close()
        logger.info("è§†é¢‘æ²¡æœ‰éŸ³é¢‘è½¨é“")
        return None
    except Exception as e:
        logger.error(f"æå–éŸ³é¢‘å¤±è´¥: {e}")
        return None


def call_qwen_image_edit(
    image_path: str,
    prompt: str,
    api_key: str,
    output_path: str,
    size: str | None = None,
) -> str:
    """
    è°ƒç”¨Qwen Image Edit APIç¼–è¾‘å›¾ç‰‡

    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        size: è¾“å‡ºå°ºå¯¸ (å¦‚ "1024*1024")

    Returns:
        è¾“å‡ºå›¾ç‰‡è·¯å¾„
    """
    import dashscope
    from dashscope import MultiModalConversation
    import requests

    dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'

    # ç¼–ç å›¾ç‰‡
    image_base64 = encode_image_to_base64(image_path)

    messages = [
        {
            "role": "user",
            "content": [
                {"image": image_base64},
                {"text": prompt}
            ]
        }
    ]

    # æ„å»ºè¯·æ±‚å‚æ•°
    kwargs = {
        "api_key": api_key,
        "model": "qwen-image-edit-plus",
        "messages": messages,
        "stream": False,
        "n": 1,
        "watermark": False,
        "prompt_extend": True,
    }

    if size:
        kwargs["size"] = size

    logger.debug(f"è°ƒç”¨Qwen APIå¤„ç†å›¾ç‰‡: {image_path}")
    response = MultiModalConversation.call(**kwargs)

    if response.status_code == 200:
        # è·å–ç”Ÿæˆçš„å›¾ç‰‡URL
        image_url = response.output.choices[0].message.content[0]['image']
        logger.debug(f"APIè¿”å›æˆåŠŸï¼Œæ­£åœ¨ä¸‹è½½å›¾ç‰‡...")

        # ä¸‹è½½å›¾ç‰‡
        img_response = requests.get(image_url)
        if img_response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(img_response.content)
            logger.debug(f"å›¾ç‰‡ä¿å­˜å®Œæˆ: {output_path}")
            return output_path
        else:
            logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: HTTP {img_response.status_code}")
            raise Exception(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: HTTP {img_response.status_code}")
    else:
        logger.error(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")
        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")


def process_frames_parallel(
    frame_paths: list[str],
    prompt: str,
    api_key: str,
    output_dir: Path,
    size: str | None = None,
    max_workers: int = 3,
    progress_callback=None,
) -> list[str]:
    """
    å¹¶è¡Œå¤„ç†å¤šä¸ªå¸§

    Args:
        frame_paths: åŸå§‹å¸§è·¯å¾„åˆ—è¡¨
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        output_dir: è¾“å‡ºç›®å½•
        size: è¾“å‡ºå°ºå¯¸
        max_workers: æœ€å¤§å¹¶è¡Œæ•°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

    Returns:
        ç¼–è¾‘åçš„å¸§è·¯å¾„åˆ—è¡¨
    """
    logger.info(f"å¼€å§‹å¹¶è¡Œå¤„ç†å¸§: å…± {len(frame_paths)} å¸§, å¹¶è¡Œæ•°: {max_workers}")
    edited_dir = output_dir / "edited_frames"
    edited_dir.mkdir(exist_ok=True)

    edited_paths = [None] * len(frame_paths)
    completed = 0
    total = len(frame_paths)

    def process_single(args):
        idx, frame_path = args
        output_path = str(edited_dir / f"edited_{idx:06d}.png")
        try:
            result = call_qwen_image_edit(frame_path, prompt, api_key, output_path, size)
            return idx, result, None
        except Exception as e:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾
            shutil.copy(frame_path, output_path)
            return idx, output_path, str(e)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(process_single, (i, path)): i
                   for i, path in enumerate(frame_paths)}

        for future in as_completed(futures):
            idx, result_path, error = future.result()
            edited_paths[idx] = result_path
            completed += 1

            if error:
                logger.warning(f"å¸§ {idx} å¤„ç†å‡ºé”™: {error}")
            else:
                logger.info(f"å¸§ {idx} å¤„ç†å®Œæˆ ({completed}/{total})")

            if progress_callback:
                progress_callback(completed / total, f"å·²å¤„ç† {completed}/{total} å¸§")

    logger.info(f"æ‰€æœ‰å¸§å¤„ç†å®Œæˆ: {completed}/{total}")
    return edited_paths


def create_pan_effect_clip(
    image_path: str,
    duration: float,
    target_size: tuple[int, int],
    pan_range: float,
    fps: float,
) -> "ImageClip":
    """
    ä¸ºå•å¼ å›¾ç‰‡åˆ›å»ºå¹³ç§»åŠ¨æ•ˆçš„è§†é¢‘ç‰‡æ®µ

    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        duration: ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
        target_size: ç›®æ ‡å°ºå¯¸ (å®½åº¦, é«˜åº¦)
        pan_range: å¹³ç§»èŒƒå›´æ¯”ä¾‹ï¼ˆå¦‚ 0.05 è¡¨ç¤º 5%ï¼‰
        fps: å¸§ç‡

    Returns:
        å¸¦å¹³ç§»åŠ¨æ•ˆçš„è§†é¢‘ç‰‡æ®µ
    """
    from moviepy import ImageClip

    # åŠ è½½åŸå›¾å¹¶æ”¾å¤§
    img = Image.open(image_path)
    original_size = img.size

    # è®¡ç®—æ”¾å¤§åçš„å°ºå¯¸ï¼ˆæ”¾å¤§ pan_range * 2 ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç§»åŠ¨ç©ºé—´ï¼‰
    scale_factor = 1 + pan_range * 2
    enlarged_size = (
        int(target_size[0] * scale_factor),
        int(target_size[1] * scale_factor),
    )

    # æ”¾å¤§å›¾ç‰‡
    img_enlarged = img.resize(enlarged_size, Image.Resampling.LANCZOS)
    img.close()

    # ä¿å­˜æ”¾å¤§åçš„ä¸´æ—¶å›¾ç‰‡
    temp_dir = Path(image_path).parent
    temp_path = temp_dir / f"_temp_enlarged_{Path(image_path).stem}.png"
    img_enlarged.save(temp_path)
    img_enlarged.close()

    # è®¡ç®—æœ€å¤§åç§»é‡
    max_offset_x = enlarged_size[0] - target_size[0]
    max_offset_y = enlarged_size[1] - target_size[1]

    # éšæœºé€‰æ‹©å¹³ç§»æ–¹å‘ï¼š0=å·¦åˆ°å³, 1=å³åˆ°å·¦, 2=ä¸Šåˆ°ä¸‹, 3=ä¸‹åˆ°ä¸Š
    direction = random.randint(0, 3)

    # è®¾ç½®èµ·å§‹å’Œç»“æŸä½ç½®
    if direction == 0:  # å·¦åˆ°å³
        start_x, end_x = 0, max_offset_x
        start_y = end_y = max_offset_y // 2
    elif direction == 1:  # å³åˆ°å·¦
        start_x, end_x = max_offset_x, 0
        start_y = end_y = max_offset_y // 2
    elif direction == 2:  # ä¸Šåˆ°ä¸‹
        start_x = end_x = max_offset_x // 2
        start_y, end_y = 0, max_offset_y
    else:  # ä¸‹åˆ°ä¸Š
        start_x = end_x = max_offset_x // 2
        start_y, end_y = max_offset_y, 0

    # åˆ›å»ºå›¾ç‰‡clip
    clip = ImageClip(str(temp_path)).with_duration(duration)

    # å®šä¹‰è£å‰ªå‡½æ•°å®ç°å¹³ç§»æ•ˆæœ
    def make_frame(get_frame, t):
        # è®¡ç®—å½“å‰æ—¶é—´çš„è¿›åº¦ï¼ˆ0åˆ°1ï¼‰
        progress = t / duration if duration > 0 else 0
        # çº¿æ€§æ’å€¼è®¡ç®—å½“å‰åç§»
        current_x = int(start_x + (end_x - start_x) * progress)
        current_y = int(start_y + (end_y - start_y) * progress)
        # è·å–å½“å‰å¸§å¹¶è£å‰ª
        frame = get_frame(t)
        cropped = frame[current_y:current_y + target_size[1], current_x:current_x + target_size[0]]
        return cropped

    # åº”ç”¨å¹³ç§»æ•ˆæœ
    clip = clip.transform(make_frame)

    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    if temp_path.exists():
        temp_path.unlink()

    return clip


def create_video_from_frames(
    frame_paths: list[str],
    output_path: str,
    fps: float,
    frame_duration: float,
    audio_path: str | None = None,
    pan_range: float = 0.0,
) -> str:
    """
    ä»å¸§åºåˆ—åˆ›å»ºè§†é¢‘

    Args:
        frame_paths: å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        fps: è¾“å‡ºè§†é¢‘å¸§ç‡ï¼ˆå¦‚24fpsä¿è¯æµç•…ï¼‰
        frame_duration: æ¯å¼ å›¾ç‰‡çš„æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        pan_range: å¹³ç§»åŠ¨æ•ˆèŒƒå›´æ¯”ä¾‹ï¼ˆå¦‚ 0.05 è¡¨ç¤º 5%ï¼‰ï¼Œ0 è¡¨ç¤ºæ— åŠ¨æ•ˆ

    Returns:
        è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    pan_enabled = pan_range > 0
    logger.info(f"å¼€å§‹åˆ›å»ºè§†é¢‘: {len(frame_paths)} å¸§, {fps}fps, æ¯å¸§æ˜¾ç¤º{frame_duration}ç§’, å¹³ç§»åŠ¨æ•ˆ: {'å¯ç”¨ ' + str(int(pan_range*100)) + '%' if pan_enabled else 'å…³é—­'}")
    from moviepy import ImageSequenceClip, AudioFileClip, concatenate_videoclips

    # æ£€æŸ¥å¹¶ç»Ÿä¸€æ‰€æœ‰å¸§çš„å°ºå¯¸
    logger.info("æ£€æŸ¥å¸§å°ºå¯¸...")
    frame_sizes = []
    for path in frame_paths:
        img = Image.open(path)
        frame_sizes.append(img.size)
        img.close()

    # ä½¿ç”¨ç¬¬ä¸€å¸§çš„å°ºå¯¸ä½œä¸ºç›®æ ‡å°ºå¯¸
    target_size = frame_sizes[0]
    size_mismatch = any(size != target_size for size in frame_sizes)

    if size_mismatch:
        logger.warning(f"æ£€æµ‹åˆ°å¸§å°ºå¯¸ä¸ä¸€è‡´ï¼Œå°†ç»Ÿä¸€è°ƒæ•´ä¸º {target_size[0]}x{target_size[1]}")
        for i, (path, size) in enumerate(zip(frame_paths, frame_sizes)):
            if size != target_size:
                logger.debug(f"è°ƒæ•´å¸§ {i} å°ºå¯¸: {size} -> {target_size}")
                img = Image.open(path)
                img_resized = img.resize(target_size, Image.Resampling.LANCZOS)
                img_resized.save(path)
                img.close()
                img_resized.close()
        logger.info("å¸§å°ºå¯¸ç»Ÿä¸€å®Œæˆ")

    # åˆ›å»ºè§†é¢‘
    if pan_enabled:
        # ä½¿ç”¨å¹³ç§»åŠ¨æ•ˆï¼šä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºå¸¦å¹³ç§»æ•ˆæœçš„clipï¼Œç„¶åæ‹¼æ¥
        logger.info("æ­£åœ¨ä¸ºæ¯å¸§åˆ›å»ºå¹³ç§»åŠ¨æ•ˆ...")
        clips = []
        for i, frame_path in enumerate(frame_paths):
            pan_clip = create_pan_effect_clip(
                frame_path,
                duration=frame_duration,
                target_size=target_size,
                pan_range=pan_range,
                fps=fps,
            )
            clips.append(pan_clip)
            if (i + 1) % 10 == 0:
                logger.debug(f"å·²å¤„ç† {i + 1}/{len(frame_paths)} å¸§çš„å¹³ç§»åŠ¨æ•ˆ")
        # æ‹¼æ¥æ‰€æœ‰clip
        clip = concatenate_videoclips(clips, method="compose")
        logger.info(f"å¹³ç§»åŠ¨æ•ˆè§†é¢‘ç‰‡æ®µåˆ›å»ºå®Œæˆ, æ—¶é•¿: {clip.duration:.2f}ç§’")
    else:
        # æ— å¹³ç§»åŠ¨æ•ˆï¼šfps = 1/frame_duration ä½¿æ¯å¸§æ˜¾ç¤º frame_duration ç§’
        sequence_fps = 1.0 / frame_duration
        clip = ImageSequenceClip(frame_paths, fps=sequence_fps)
        logger.info(f"è§†é¢‘ç‰‡æ®µåˆ›å»ºå®Œæˆ, æ—¶é•¿: {clip.duration:.2f}ç§’")

    # æ·»åŠ éŸ³é¢‘
    audio = None
    if audio_path and os.path.exists(audio_path):
        logger.info(f"æ­£åœ¨æ·»åŠ éŸ³é¢‘: {audio_path}")
        audio = AudioFileClip(audio_path)
        # ç¡®ä¿éŸ³é¢‘é•¿åº¦ä¸è§†é¢‘åŒ¹é…
        if audio.duration > clip.duration:
            audio = audio.subclipped(0, clip.duration)
        clip = clip.with_audio(audio)
        logger.info("éŸ³é¢‘æ·»åŠ å®Œæˆ")

    # è¾“å‡ºè§†é¢‘
    logger.info(f"æ­£åœ¨ç¼–ç è¾“å‡ºè§†é¢‘: {output_path}")
    clip.write_videofile(
        output_path,
        fps=fps,
        codec='libx264',
        audio_codec='aac',
        logger=None,
    )

    clip.close()
    if audio is not None:
        audio.close()

    logger.info(f"è§†é¢‘åˆ›å»ºå®Œæˆ: {output_path}")
    return output_path


def process_video(
    video_path: str,
    interval: float,
    prompt: str,
    api_key: str,
    output_size: str,
    max_workers: int,
    pan_range: float,
    progress=gr.Progress(),
) -> tuple[str, list[tuple[str, str]], str]:
    """
    å¤„ç†è§†é¢‘çš„ä¸»å‡½æ•°

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        interval: å¸§æå–é—´éš”ï¼ˆç§’ï¼‰
        prompt: ç¼–è¾‘æŒ‡ä»¤
        api_key: APIå¯†é’¥
        output_size: è¾“å‡ºå°ºå¯¸
        max_workers: å¹¶è¡Œå¤„ç†æ•°
        pan_range: å¹³ç§»åŠ¨æ•ˆèŒƒå›´ï¼ˆ0-20%ï¼‰
        progress: è¿›åº¦å›è°ƒ

    Returns:
        (è¾“å‡ºè§†é¢‘è·¯å¾„, é¢„è§ˆå›¾ç‰‡åˆ—è¡¨, çŠ¶æ€æ¶ˆæ¯)
    """
    if not video_path:
        return None, [], "è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶"

    if not api_key:
        return None, [], "è¯·è¾“å…¥API Key"

    if not prompt:
        return None, [], "è¯·è¾“å…¥ç¼–è¾‘æŒ‡ä»¤"

    # åˆ›å»ºå·¥ä½œç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    work_dir = DEFAULT_OUTPUT_DIR / f"job_{timestamp}"
    work_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"========== å¼€å§‹å¤„ç†è§†é¢‘ ==========")
    logger.info(f"è§†é¢‘è·¯å¾„: {video_path}")
    logger.info(f"å·¥ä½œç›®å½•: {work_dir}")
    # pan_range ä» UI ä¼ å…¥çš„æ˜¯ç™¾åˆ†æ¯”å€¼ï¼ˆ0-20ï¼‰ï¼Œè½¬æ¢ä¸ºæ¯”ä¾‹ï¼ˆ0-0.20ï¼‰
    pan_range_ratio = pan_range / 100.0
    pan_range_pct = int(pan_range)
    logger.info(f"å‚æ•°: é—´éš”={interval}ç§’, å¹¶è¡Œæ•°={max_workers}, å°ºå¯¸={output_size}, å¹³ç§»åŠ¨æ•ˆ={pan_range_pct}%")

    try:
        # æ­¥éª¤1: æå–å¸§
        logger.info("[æ­¥éª¤1/4] å¼€å§‹æå–è§†é¢‘å¸§...")
        progress(0.1, desc="æ­£åœ¨æå–è§†é¢‘å¸§...")
        frame_paths, fps, (width, height) = extract_frames(video_path, interval, work_dir)

        if not frame_paths:
            logger.error("æ— æ³•ä»è§†é¢‘ä¸­æå–å¸§")
            return None, [], "æ— æ³•ä»è§†é¢‘ä¸­æå–å¸§"

        progress(0.15, desc=f"å·²æå– {len(frame_paths)} å¸§")

        # æ­¥éª¤2: æå–éŸ³é¢‘
        logger.info("[æ­¥éª¤2/4] å¼€å§‹æå–éŸ³é¢‘...")
        progress(0.2, desc="æ­£åœ¨æå–éŸ³é¢‘...")
        audio_path = extract_audio(video_path, work_dir)

        # ä¿å­˜ä»»åŠ¡é…ç½®ï¼ˆåœ¨æå–å®Œå¸§å’ŒéŸ³é¢‘åä¿å­˜ï¼Œä»¥ä¾¿åç»­é‡åšæ—¶ä½¿ç”¨ï¼‰
        save_job_config(
            job_dir=work_dir,
            video_path=video_path,
            interval=interval,
            prompt=prompt,
            output_size=output_size,
            max_workers=max_workers,
            pan_range=pan_range,
            fps=fps,
            width=width,
            height=height,
            total_frames=len(frame_paths),
            has_audio=audio_path is not None,
        )

        # æ­¥éª¤3: å¤„ç†å¸§
        logger.info("[æ­¥éª¤3/4] å¼€å§‹å¤„ç†å¸§...")
        progress(0.25, desc="æ­£åœ¨å¤„ç†å¸§...")

        # è§£æè¾“å‡ºå°ºå¯¸
        size = output_size if output_size and output_size != "åŸå§‹å°ºå¯¸" else None

        def update_progress(ratio, msg):
            # å¸§å¤„ç†å 25%-85%çš„è¿›åº¦
            progress(0.25 + ratio * 0.6, desc=msg)

        edited_paths = process_frames_parallel(
            frame_paths,
            prompt,
            api_key,
            work_dir,
            size=size,
            max_workers=max_workers,
            progress_callback=update_progress,
        )

        # æ­¥éª¤4: ç”Ÿæˆè§†é¢‘
        logger.info("[æ­¥éª¤4/4] å¼€å§‹åˆæˆè§†é¢‘...")
        progress(0.9, desc="æ­£åœ¨åˆæˆè§†é¢‘...")
        output_video_path = str(work_dir / "output.mp4")
        # fps=24 ä¿è¯è§†é¢‘æµç•…ï¼Œframe_duration=interval è®©æ¯å¼ å›¾ç‰‡æ˜¾ç¤º interval ç§’
        output_fps = 24.0
        logger.info(f"è¾“å‡ºè§†é¢‘å¸§ç‡: {output_fps:.0f}fps, æ¯å¸§æ˜¾ç¤º{interval}ç§’")
        create_video_from_frames(edited_paths, output_video_path, output_fps, interval, audio_path, pan_range_ratio)

        progress(1.0, desc="å¤„ç†å®Œæˆ!")

        # å‡†å¤‡é¢„è§ˆå›¾ç‰‡ï¼ˆæ˜¾ç¤ºåŸå›¾å’Œç¼–è¾‘åçš„å¯¹æ¯”ï¼‰
        preview_images = []
        step = max(1, len(frame_paths) // 6)  # æœ€å¤šæ˜¾ç¤º6ç»„å¯¹æ¯”
        for i in range(0, len(frame_paths), step):
            if i < len(edited_paths) and edited_paths[i]:
                preview_images.append((frame_paths[i], f"åŸå§‹å¸§ {i+1}"))
                preview_images.append((edited_paths[i], f"ç¼–è¾‘å {i+1}"))

        status = f"å¤„ç†å®Œæˆ! å…±å¤„ç† {len(frame_paths)} å¸§ï¼Œè¾“å‡ºè§†é¢‘: {output_video_path}"
        logger.info(f"========== è§†é¢‘å¤„ç†å®Œæˆ ==========")
        logger.info(f"è¾“å‡ºæ–‡ä»¶: {output_video_path}")
        return output_video_path, preview_images, status

    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {str(e)}", exc_info=True)
        return None, [], f"å¤„ç†å¤±è´¥: {str(e)}"


def create_ui():
    """åˆ›å»ºGradioç•Œé¢"""

    with gr.Blocks(title="è§†é¢‘é£æ ¼ç¼–è¾‘å™¨", theme=gr.themes.Soft()) as app:
        gr.Markdown("""
        # ğŸ¬ è§†é¢‘é£æ ¼ç¼–è¾‘å™¨

        ä½¿ç”¨é€šä¹‰åƒé—® Qwen Image Edit API å¯¹è§†é¢‘è¿›è¡Œé£æ ¼è½¬æ¢ã€‚
        """)

        # å…±äº«çš„ API Key è¾“å…¥
        api_key_input = gr.Textbox(
            label="DashScope API Key",
            placeholder="è¯·è¾“å…¥æ‚¨çš„API Key",
            type="password",
            value=os.getenv("DASHSCOPE_API_KEY", ""),
        )

        with gr.Tabs():
            # ==================== æ–°ä»»åŠ¡æ ‡ç­¾é¡µ ====================
            with gr.TabItem("ğŸ†• æ–°ä»»åŠ¡"):
                gr.Markdown("ä¸Šä¼ è§†é¢‘ï¼ŒæŒ‰æŒ‡å®šæ—¶é—´é—´éš”æå–å¸§ï¼Œä½¿ç”¨AIç¼–è¾‘æ¯ä¸€å¸§ï¼Œç„¶åé‡æ–°åˆæˆè§†é¢‘ã€‚")

                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“ è¾“å…¥è®¾ç½®")

                        video_input = gr.Video(
                            label="ä¸Šä¼ è§†é¢‘",
                            sources=["upload"],
                        )

                        prompt_input = gr.Textbox(
                            label="ç¼–è¾‘æŒ‡ä»¤",
                            placeholder="æè¿°æ‚¨æƒ³è¦çš„è§†è§’/æ™¯åˆ«å˜åŒ–ï¼Œä¾‹å¦‚ï¼šå°†ç”»é¢è½¬æ¢ä¸ºä¿¯è§†è§’åº¦ï¼Œå¢åŠ æ™¯æ·±æ•ˆæœ",
                            lines=3,
                            value="å°†ç”»é¢è½¬æ¢ä¸ºç”µå½±çº§åˆ«çš„å¹¿è§’é•œå¤´æ•ˆæœï¼Œå¢å¼ºæ™¯æ·±å’Œç©ºé—´æ„Ÿ",
                        )

                        with gr.Row():
                            interval_input = gr.Slider(
                                label="å¸§æå–é—´éš”ï¼ˆç§’ï¼‰",
                                minimum=0.1,
                                maximum=10.0,
                                value=1.0,
                                step=0.1,
                                info="é—´éš”è¶Šå°ï¼Œå¸§æ•°è¶Šå¤šï¼Œå¤„ç†æ—¶é—´è¶Šé•¿",
                            )

                            workers_input = gr.Slider(
                                label="å¹¶è¡Œå¤„ç†æ•°",
                                minimum=1,
                                maximum=5,
                                value=2,
                                step=1,
                                info="åŒæ—¶å¤„ç†çš„å¸§æ•°ï¼Œå»ºè®®2-3",
                            )

                        size_input = gr.Dropdown(
                            label="è¾“å‡ºå°ºå¯¸",
                            choices=["åŸå§‹å°ºå¯¸", "512*512", "768*768", "1024*1024", "1024*768", "768*1024"],
                            value="åŸå§‹å°ºå¯¸",
                            info="è®¾ç½®ç¼–è¾‘åå›¾ç‰‡çš„åˆ†è¾¨ç‡",
                        )

                        pan_range_input = gr.Slider(
                            label="å¹³ç§»åŠ¨æ•ˆèŒƒå›´ï¼ˆ%ï¼‰",
                            minimum=0,
                            maximum=20,
                            value=0,
                            step=1,
                            info="å›¾ç‰‡å¹³ç§»èŒƒå›´ï¼Œ0è¡¨ç¤ºå…³é—­ï¼Œ5-10%æ•ˆæœè¾ƒè‡ªç„¶ï¼Œæ–¹å‘éšæœº",
                        )

                        process_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary", size="lg")

                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“º è¾“å‡ºç»“æœ")

                        status_output = gr.Textbox(
                            label="å¤„ç†çŠ¶æ€",
                            interactive=False,
                        )

                        video_output = gr.Video(
                            label="è¾“å‡ºè§†é¢‘",
                        )

                # é¢„è§ˆåŒºåŸŸ
                gr.Markdown("### ğŸ–¼ï¸ å¸§é¢„è§ˆï¼ˆåŸå›¾ vs ç¼–è¾‘åï¼‰")
                preview_gallery = gr.Gallery(
                    label="å¸§å¯¹æ¯”é¢„è§ˆ",
                    columns=4,
                    rows=2,
                    height="auto",
                    object_fit="contain",
                )

            # ==================== é‡åšä»»åŠ¡æ ‡ç­¾é¡µ ====================
            with gr.TabItem("ğŸ”„ é‡åšä»»åŠ¡"):
                gr.Markdown("""
                è¾“å…¥å·²æœ‰ä»»åŠ¡çš„æ–‡ä»¶å¤¹åï¼Œæ£€æŸ¥å¹¶è¡¥å…¨ç¼ºå¤±çš„éƒ¨åˆ†ã€‚

                **åŠŸèƒ½è¯´æ˜**ï¼š
                - æ£€æŸ¥åŸå§‹å¸§æ˜¯å¦å®Œæ•´ï¼Œç¼ºå¤±åˆ™ä»è§†é¢‘é‡æ–°æå–
                - æ£€æŸ¥ç¼–è¾‘å¸§æ˜¯å¦å®Œæ•´ï¼Œç¼ºå¤±åˆ™é‡æ–°è°ƒç”¨ API ç”Ÿæˆ
                - æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œç¼ºå¤±åˆ™é‡æ–°æå–
                - é‡æ–°åˆæˆæœ€ç»ˆè§†é¢‘
                """)

                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“‚ ä»»åŠ¡è®¾ç½®")

                        job_folder_input = gr.Textbox(
                            label="Job æ–‡ä»¶å¤¹å",
                            placeholder="ä¾‹å¦‚: job_20260116_203414",
                            info="è¾“å…¥ output ç›®å½•ä¸‹çš„ä»»åŠ¡æ–‡ä»¶å¤¹å",
                        )

                        check_btn = gr.Button("ğŸ” æ£€æŸ¥ä»»åŠ¡çŠ¶æ€", variant="secondary")

                        job_status_output = gr.Textbox(
                            label="ä»»åŠ¡çŠ¶æ€",
                            lines=12,
                            interactive=False,
                        )

                        gr.Markdown("### âš™ï¸ é‡åšé€‰é¡¹")

                        retry_prompt_input = gr.Textbox(
                            label="è¦†ç›–ç¼–è¾‘æŒ‡ä»¤ï¼ˆå¯é€‰ï¼‰",
                            placeholder="ç•™ç©ºåˆ™ä½¿ç”¨åŸæœ‰çš„ç¼–è¾‘æŒ‡ä»¤",
                            lines=2,
                        )

                        retry_workers_input = gr.Slider(
                            label="å¹¶è¡Œå¤„ç†æ•°",
                            minimum=1,
                            maximum=5,
                            value=2,
                            step=1,
                            info="å¤„ç†ç¼ºå¤±å¸§æ—¶çš„å¹¶è¡Œæ•°",
                        )

                        regenerate_video_input = gr.Checkbox(
                            label="å¼ºåˆ¶é‡æ–°ç”Ÿæˆè§†é¢‘",
                            value=True,
                            info="å³ä½¿è§†é¢‘å·²å­˜åœ¨ä¹Ÿé‡æ–°ç”Ÿæˆ",
                        )

                        retry_btn = gr.Button("ğŸ”„ å¼€å§‹é‡åš", variant="primary", size="lg")

                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“º é‡åšç»“æœ")

                        retry_status_output = gr.Textbox(
                            label="é‡åšçŠ¶æ€",
                            interactive=False,
                        )

                        retry_video_output = gr.Video(
                            label="è¾“å‡ºè§†é¢‘",
                        )

                # é¢„è§ˆåŒºåŸŸ
                gr.Markdown("### ğŸ–¼ï¸ å¸§é¢„è§ˆï¼ˆåŸå›¾ vs ç¼–è¾‘åï¼‰")
                retry_preview_gallery = gr.Gallery(
                    label="å¸§å¯¹æ¯”é¢„è§ˆ",
                    columns=4,
                    rows=2,
                    height="auto",
                    object_fit="contain",
                )

        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ## æ–°ä»»åŠ¡ä½¿ç”¨æ­¥éª¤

            1. **è·å–API Key**: å‰å¾€ [é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°](https://bailian.console.alibabacloud.com/) æ³¨å†Œå¹¶è·å– DashScope API Key
            2. **ä¸Šä¼ è§†é¢‘**: æ”¯æŒå¸¸è§è§†é¢‘æ ¼å¼ï¼ˆMP4, AVI, MOVç­‰ï¼‰
            3. **è®¾ç½®å‚æ•°**:
               - **å¸§æå–é—´éš”**: å»ºè®®0.5-2ç§’ï¼Œé—´éš”è¶Šå°æ•ˆæœè¶Šæµç•…ä½†å¤„ç†æ—¶é—´è¶Šé•¿
               - **ç¼–è¾‘æŒ‡ä»¤**: æè¿°æ‚¨æƒ³è¦çš„è§†è§‰æ•ˆæœå˜åŒ–
               - **å¹¶è¡Œå¤„ç†æ•°**: å»ºè®®2-3ï¼Œè¿‡é«˜å¯èƒ½è§¦å‘APIé™æµ
            4. **å¼€å§‹å¤„ç†**: ç‚¹å‡»æŒ‰é’®åç­‰å¾…å¤„ç†å®Œæˆ
            5. **æŸ¥çœ‹ç»“æœ**: é¢„è§ˆç¼–è¾‘åçš„å¸§å¹¶ä¸‹è½½è¾“å‡ºè§†é¢‘

            ## é‡åšä»»åŠ¡ä½¿ç”¨æ­¥éª¤

            1. **è¾“å…¥ä»»åŠ¡æ–‡ä»¶å¤¹å**: åœ¨ output ç›®å½•ä¸‹æ‰¾åˆ°ä¹‹å‰çš„ä»»åŠ¡æ–‡ä»¶å¤¹åï¼ˆå¦‚ job_20260116_203414ï¼‰
            2. **æ£€æŸ¥çŠ¶æ€**: ç‚¹å‡»"æ£€æŸ¥ä»»åŠ¡çŠ¶æ€"æŸ¥çœ‹å“ªäº›éƒ¨åˆ†ç¼ºå¤±
            3. **è®¾ç½®é€‰é¡¹**: å¯ä»¥è¦†ç›–åŸæœ‰çš„ç¼–è¾‘æŒ‡ä»¤ï¼Œæˆ–ä½¿ç”¨åŸé…ç½®
            4. **å¼€å§‹é‡åš**: ç³»ç»Ÿä¼šè‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„éƒ¨åˆ†å¹¶é‡æ–°ç”Ÿæˆè§†é¢‘

            ## ç¼–è¾‘æŒ‡ä»¤ç¤ºä¾‹

            - å°†ç”»é¢è½¬æ¢ä¸ºä¿¯è§†è§’åº¦
            - å¢åŠ ç”µå½±çº§åˆ«çš„æ™¯æ·±æ•ˆæœ
            - è½¬æ¢ä¸ºå¹¿è§’é•œå¤´è§†è§’
            - å¢å¼ºç”»é¢çš„ç©ºé—´å±‚æ¬¡æ„Ÿ
            - å°†è¿‘æ™¯è½¬æ¢ä¸ºä¸­æ™¯æ„å›¾
            - æ·»åŠ æŸ”å’Œçš„èƒŒæ™¯è™šåŒ–æ•ˆæœ

            ## æ³¨æ„äº‹é¡¹

            - è§†é¢‘è¾ƒé•¿æ—¶å¤„ç†æ—¶é—´å¯èƒ½è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…
            - APIè°ƒç”¨ä¼šäº§ç”Ÿè´¹ç”¨ï¼Œè¯·æ³¨æ„æ§åˆ¶å¸§æ•°
            - å»ºè®®å…ˆç”¨çŸ­è§†é¢‘æµ‹è¯•æ•ˆæœ
            - é‡åšä»»åŠ¡éœ€è¦åŸå§‹è§†é¢‘æ–‡ä»¶ä»åœ¨åŸè·¯å¾„ï¼Œå¦åˆ™æ— æ³•è¡¥å…¨åŸå§‹å¸§
            """)

        # ç»‘å®šäº‹ä»¶ - æ–°ä»»åŠ¡
        process_btn.click(
            fn=process_video,
            inputs=[
                video_input,
                interval_input,
                prompt_input,
                api_key_input,
                size_input,
                workers_input,
                pan_range_input,
            ],
            outputs=[video_output, preview_gallery, status_output],
            show_progress=True,
        )

        # ç»‘å®šäº‹ä»¶ - æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        check_btn.click(
            fn=check_job_status,
            inputs=[job_folder_input],
            outputs=[job_status_output],
        )

        # ç»‘å®šäº‹ä»¶ - é‡åšä»»åŠ¡
        retry_btn.click(
            fn=retry_job,
            inputs=[
                job_folder_input,
                api_key_input,
                retry_prompt_input,
                retry_workers_input,
                regenerate_video_input,
            ],
            outputs=[retry_video_output, retry_preview_gallery, retry_status_output],
            show_progress=True,
        )

    return app


def main():
    """ä¸»å‡½æ•°"""
    app = create_ui()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
    )


if __name__ == "__main__":
    main()
